2021-12-23 23:11:00,537 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 55] Starting HdfsApplication on DESKTOP-ORCB6UD with PID 12028 (C:\Users\UI\Desktop\bd-platform\springboot-hadoop\target\classes started by UI in C:\Users\UI\Desktop\bd-platform)
2021-12-23 23:11:00,540 INFO [main] com.bigdata.HdfsApplication [SpringApplication.java : 651] No active profile set, falling back to default profiles: default
2021-12-23 23:11:02,403 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 108] Tomcat initialized with port(s): 8080 (http)
2021-12-23 23:11:02,412 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Initializing ProtocolHandler ["http-nio-8080"]
2021-12-23 23:11:02,413 INFO [main] o.a.catalina.core.StandardService [DirectJDKLog.java : 173] Starting service [Tomcat]
2021-12-23 23:11:02,413 INFO [main] o.a.catalina.core.StandardEngine [DirectJDKLog.java : 173] Starting Servlet engine: [Apache Tomcat/9.0.39]
2021-12-23 23:11:02,511 INFO [main] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring embedded WebApplicationContext
2021-12-23 23:11:02,511 INFO [main] o.s.b.w.s.c.ServletWebServerApplicationContext [ServletWebServerApplicationContext.java : 285] Root WebApplicationContext: initialization completed in 1930 ms
2021-12-23 23:11:02,668 INFO [main] o.s.s.c.ThreadPoolTaskExecutor [ExecutorConfigurationSupport.java : 181] Initializing ExecutorService 'applicationTaskExecutor'
2021-12-23 23:11:02,949 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Starting ProtocolHandler ["http-nio-8080"]
2021-12-23 23:11:02,985 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 220] Tomcat started on port(s): 8080 (http) with context path ''
2021-12-23 23:11:02,992 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 61] Started HdfsApplication in 3.073 seconds (JVM running for 4.615)
2021-12-23 23:46:22,034 INFO [http-nio-8080-exec-3] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-12-23 23:46:22,035 INFO [http-nio-8080-exec-3] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 525] Initializing Servlet 'dispatcherServlet'
2021-12-23 23:46:22,042 INFO [http-nio-8080-exec-3] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 547] Completed initialization in 7 ms
2021-12-23 23:46:23,367 WARN [http-nio-8080-exec-3] org.apache.hadoop.util.Shell [Shell.java : 694] Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:549)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:570)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:593)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:690)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3533)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3528)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:216)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:213)
	at com.bigdata.hadoop.HdfsService.getFileSystem(HdfsService.java:132)
	at com.bigdata.hadoop.HdfsService.uploadFile(HdfsService.java:342)
	at com.bigdata.controller.HdfsAction.uploadFile(HdfsAction.java:194)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:652)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:469)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517)
	... 64 common frames omitted
2021-12-23 23:48:37,207 INFO [http-nio-8080-exec-2] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-23 23:48:37,484 INFO [http-nio-8080-exec-2] o.a.c.b.FluentPropertyBeanIntrospector [FluentPropertyBeanIntrospector.java : 147] Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-12-23 23:48:37,498 WARN [http-nio-8080-exec-2] o.a.h.metrics2.impl.MetricsConfig [MetricsConfig.java : 134] Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-23 23:48:37,519 INFO [http-nio-8080-exec-2] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 374] Scheduled Metric snapshot period at 10 second(s).
2021-12-23 23:48:37,520 INFO [http-nio-8080-exec-2] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 191] JobTracker metrics system started
2021-12-23 23:48:37,985 WARN [http-nio-8080-exec-2] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-23 23:48:38,025 WARN [http-nio-8080-exec-2] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-23 23:48:38,074 INFO [http-nio-8080-exec-2] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-23 23:48:38,167 INFO [http-nio-8080-exec-2] o.a.h.m.l.i.CombineFileInputFormat [CombineFileInputFormat.java : 428] DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 686
2021-12-23 23:48:38,191 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-23 23:48:38,259 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local32065182_0001
2021-12-23 23:48:38,259 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-23 23:48:38,397 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-23 23:48:38,398 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local32065182_0001
2021-12-23 23:48:38,402 INFO [Thread-24] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-23 23:48:38,408 INFO [Thread-24] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-23 23:48:38,409 INFO [Thread-24] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-23 23:48:38,409 INFO [Thread-24] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-23 23:48:38,599 INFO [Thread-24] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-23 23:48:38,601 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local32065182_0001_m_000000_0
2021-12-23 23:48:38,625 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-23 23:48:38,625 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-23 23:48:38,633 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-23 23:48:38,634 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-23 23:48:38,668 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: Paths:/user/hadoop/test/group_count.txt:0+686
2021-12-23 23:48:38,743 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-23 23:48:38,744 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-23 23:48:38,744 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-23 23:48:38,744 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-23 23:48:38,744 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-23 23:48:38,748 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-23 23:48:39,285 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 
2021-12-23 23:48:39,285 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-23 23:48:39,286 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1498] Spilling map output
2021-12-23 23:48:39,286 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1499] bufstart = 0; bufend = 1568; bufvoid = 104857600
2021-12-23 23:48:39,286 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1501] kvstart = 26214396(104857584); kvend = 26213504(104854016); length = 893/6553600
2021-12-23 23:48:39,301 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1696] Finished spill 0
2021-12-23 23:48:39,314 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local32065182_0001_m_000000_0 is done. And is in the process of committing
2021-12-23 23:48:39,317 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map
2021-12-23 23:48:39,318 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local32065182_0001_m_000000_0' done.
2021-12-23 23:48:39,341 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local32065182_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=878
		FILE: Number of bytes written=489364
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=686
		HDFS: Number of bytes written=686
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=14
		Map output records=224
		Map output bytes=1568
		Map output materialized bytes=69
		Input split bytes=146
		Combine input records=224
		Combine output records=7
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=195
		Total committed heap usage (bytes)=469762048
	File Input Format Counters 
		Bytes Read=0
2021-12-23 23:48:39,341 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 277] Finishing task: attempt_local32065182_0001_m_000000_0
2021-12-23 23:48:39,342 INFO [Thread-24] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-23 23:48:39,343 INFO [Thread-24] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for reduce tasks
2021-12-23 23:48:39,344 INFO [pool-9-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 330] Starting task: attempt_local32065182_0001_r_000000_0
2021-12-23 23:48:39,352 INFO [pool-9-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-23 23:48:39,353 INFO [pool-9-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-23 23:48:39,353 INFO [pool-9-thread-1] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-23 23:48:39,353 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-23 23:48:39,354 INFO [pool-9-thread-1] org.apache.hadoop.mapred.ReduceTask [ReduceTask.java : 363] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3a67507c
2021-12-23 23:48:39,356 WARN [pool-9-thread-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-23 23:48:39,362 INFO [pool-9-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 208] MergerManager: memoryLimit=2651586560, maxSingleShuffleLimit=662896640, mergeThreshold=1750047232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-12-23 23:48:39,364 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 61] attempt_local32065182_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-12-23 23:48:39,387 INFO [localfetcher#1] o.a.h.m.task.reduce.LocalFetcher [LocalFetcher.java : 145] localfetcher#1 about to shuffle output of map attempt_local32065182_0001_m_000000_0 decomp: 65 len: 69 to MEMORY
2021-12-23 23:48:39,396 INFO [localfetcher#1] o.a.h.m.t.reduce.InMemoryMapOutput [InMemoryMapOutput.java : 94] Read 65 bytes from map-output for attempt_local32065182_0001_m_000000_0
2021-12-23 23:48:39,399 INFO [localfetcher#1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 323] closeInMemoryFile -> map-output of size: 65, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->65
2021-12-23 23:48:39,400 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 76] EventFetcher is interrupted.. Returning
2021-12-23 23:48:39,401 INFO [pool-9-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-23 23:48:39,401 INFO [pool-9-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 695] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-12-23 23:48:39,409 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-23 23:48:39,409 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 60 bytes
2021-12-23 23:48:39,410 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local32065182_0001 running in uber mode : false
2021-12-23 23:48:39,411 INFO [pool-9-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 762] Merged 1 segments, 65 bytes to disk to satisfy reduce memory limit
2021-12-23 23:48:39,411 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 0%
2021-12-23 23:48:39,412 INFO [pool-9-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 792] Merging 1 files, 69 bytes from disk
2021-12-23 23:48:39,412 INFO [pool-9-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 807] Merging 0 segments, 0 bytes from memory into reduce
2021-12-23 23:48:39,412 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-23 23:48:39,415 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 60 bytes
2021-12-23 23:48:39,415 INFO [pool-9-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-23 23:48:39,543 INFO [pool-9-thread-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-12-23 23:48:39,895 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local32065182_0001_r_000000_0 is done. And is in the process of committing
2021-12-23 23:48:39,900 INFO [pool-9-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-23 23:48:39,901 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1409] Task attempt_local32065182_0001_r_000000_0 is allowed to commit now
2021-12-23 23:48:40,045 INFO [pool-9-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 598] Saved output of task 'attempt_local32065182_0001_r_000000_0' to hdfs://localhost:9000/output/groupSort
2021-12-23 23:48:40,047 INFO [pool-9-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-23 23:48:40,047 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local32065182_0001_r_000000_0' done.
2021-12-23 23:48:40,048 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local32065182_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1048
		FILE: Number of bytes written=489433
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=686
		HDFS: Number of bytes written=725
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=69
		Reduce input records=7
		Reduce output records=7
		Spilled Records=7
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=469762048
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=39
2021-12-23 23:48:40,049 INFO [pool-9-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 353] Finishing task: attempt_local32065182_0001_r_000000_0
2021-12-23 23:48:40,050 INFO [Thread-24] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] reduce task executor complete.
2021-12-23 23:48:40,417 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 100%
2021-12-23 23:48:41,430 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1658] Job job_local32065182_0001 completed successfully
2021-12-23 23:48:41,449 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 35
	File System Counters
		FILE: Number of bytes read=1926
		FILE: Number of bytes written=978797
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1372
		HDFS: Number of bytes written=1411
		HDFS: Number of read operations=21
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=14
		Map output records=224
		Map output bytes=1568
		Map output materialized bytes=69
		Input split bytes=146
		Combine input records=224
		Combine output records=7
		Reduce input groups=7
		Reduce shuffle bytes=69
		Reduce input records=7
		Reduce output records=7
		Spilled Records=14
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=195
		Total committed heap usage (bytes)=939524096
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=39
