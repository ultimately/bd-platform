2021-12-26 01:07:48,159 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 55] Starting HdfsApplication on DESKTOP-ORCB6UD with PID 26308 (C:\Users\UI\Desktop\bd-platform\springboot-hadoop\target\classes started by UI in C:\Users\UI\Desktop\bd-platform)
2021-12-26 01:07:48,165 INFO [main] com.bigdata.HdfsApplication [SpringApplication.java : 651] No active profile set, falling back to default profiles: default
2021-12-26 01:07:49,759 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 108] Tomcat initialized with port(s): 8080 (http)
2021-12-26 01:07:49,775 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Initializing ProtocolHandler ["http-nio-8080"]
2021-12-26 01:07:49,776 INFO [main] o.a.catalina.core.StandardService [DirectJDKLog.java : 173] Starting service [Tomcat]
2021-12-26 01:07:49,776 INFO [main] o.a.catalina.core.StandardEngine [DirectJDKLog.java : 173] Starting Servlet engine: [Apache Tomcat/9.0.39]
2021-12-26 01:07:49,926 INFO [main] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring embedded WebApplicationContext
2021-12-26 01:07:49,926 INFO [main] o.s.b.w.s.c.ServletWebServerApplicationContext [ServletWebServerApplicationContext.java : 285] Root WebApplicationContext: initialization completed in 1684 ms
2021-12-26 01:07:50,146 INFO [main] o.s.s.c.ThreadPoolTaskExecutor [ExecutorConfigurationSupport.java : 181] Initializing ExecutorService 'applicationTaskExecutor'
2021-12-26 01:07:50,330 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Starting ProtocolHandler ["http-nio-8080"]
2021-12-26 01:07:50,354 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 220] Tomcat started on port(s): 8080 (http) with context path ''
2021-12-26 01:07:50,362 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 61] Started HdfsApplication in 2.766 seconds (JVM running for 4.246)
2021-12-26 01:07:58,725 INFO [http-nio-8080-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-12-26 01:07:58,725 INFO [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 525] Initializing Servlet 'dispatcherServlet'
2021-12-26 01:07:58,731 INFO [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 547] Completed initialization in 6 ms
2021-12-26 01:07:59,139 WARN [http-nio-8080-exec-2] org.apache.hadoop.util.Shell [Shell.java : 694] Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:549)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:570)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:593)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:690)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3533)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3528)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:216)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:213)
	at com.bigdata.hadoop.HdfsService.getFileSystem(HdfsService.java:156)
	at com.bigdata.hadoop.HdfsService.existFile(HdfsService.java:191)
	at com.bigdata.hadoop.MapReduceService.wordCount(MapReduceService.java:30)
	at com.bigdata.controller.MapReduceAction.wordCount(MapReduceAction.java:36)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:652)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:469)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517)
	... 65 common frames omitted
2021-12-26 01:08:01,400 INFO [http-nio-8080-exec-2] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 01:08:01,791 INFO [http-nio-8080-exec-2] o.a.c.b.FluentPropertyBeanIntrospector [FluentPropertyBeanIntrospector.java : 147] Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-12-26 01:08:01,820 WARN [http-nio-8080-exec-2] o.a.h.metrics2.impl.MetricsConfig [MetricsConfig.java : 134] Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 01:08:01,834 INFO [http-nio-8080-exec-2] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 374] Scheduled Metric snapshot period at 10 second(s).
2021-12-26 01:08:01,835 INFO [http-nio-8080-exec-2] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 191] JobTracker metrics system started
2021-12-26 01:08:02,311 WARN [http-nio-8080-exec-2] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 01:08:02,334 WARN [http-nio-8080-exec-2] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 01:08:02,371 INFO [http-nio-8080-exec-2] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 01:08:02,587 INFO [http-nio-8080-exec-2] o.a.h.m.l.i.CombineFileInputFormat [CombineFileInputFormat.java : 428] DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 290
2021-12-26 01:08:02,610 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 01:08:02,672 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local2015299545_0001
2021-12-26 01:08:02,673 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 01:08:02,852 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 01:08:02,853 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local2015299545_0001
2021-12-26 01:08:02,872 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 01:08:02,880 INFO [Thread-21] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:08:02,880 INFO [Thread-21] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:08:02,881 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 01:08:03,122 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 01:08:03,123 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local2015299545_0001_m_000000_0
2021-12-26 01:08:03,172 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:08:03,173 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:08:03,181 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:08:03,182 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:08:03,198 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: Paths:/user/hadoop/test/product.txt:0+290
2021-12-26 01:08:03,251 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 01:08:03,252 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 01:08:03,252 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 01:08:03,252 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 01:08:03,252 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 01:08:03,258 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 01:08:03,845 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 
2021-12-26 01:08:03,845 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 01:08:03,845 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1498] Spilling map output
2021-12-26 01:08:03,845 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1499] bufstart = 0; bufend = 412; bufvoid = 104857600
2021-12-26 01:08:03,846 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1501] kvstart = 26214396(104857584); kvend = 26214260(104857040); length = 137/6553600
2021-12-26 01:08:03,863 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1696] Finished spill 0
2021-12-26 01:08:03,878 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local2015299545_0001_m_000000_0 is done. And is in the process of committing
2021-12-26 01:08:03,880 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map
2021-12-26 01:08:03,881 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local2015299545_0001_m_000000_0' done.
2021-12-26 01:08:03,887 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local2015299545_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=188
		FILE: Number of bytes written=494532
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Spilled Records=31
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=208
		Total committed heap usage (bytes)=635961344
	File Input Format Counters 
		Bytes Read=0
2021-12-26 01:08:03,887 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local2015299545_0001 running in uber mode : false
2021-12-26 01:08:03,887 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 277] Finishing task: attempt_local2015299545_0001_m_000000_0
2021-12-26 01:08:03,888 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 01:08:03,888 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 0%
2021-12-26 01:08:03,889 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for reduce tasks
2021-12-26 01:08:03,889 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 330] Starting task: attempt_local2015299545_0001_r_000000_0
2021-12-26 01:08:03,898 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:08:03,898 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:08:03,898 INFO [pool-8-thread-1] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:08:03,899 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:08:03,901 INFO [pool-8-thread-1] org.apache.hadoop.mapred.ReduceTask [ReduceTask.java : 363] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@668e3113
2021-12-26 01:08:03,903 WARN [pool-8-thread-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 01:08:03,910 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 208] MergerManager: memoryLimit=2651586560, maxSingleShuffleLimit=662896640, mergeThreshold=1750047232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-12-26 01:08:03,912 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 61] attempt_local2015299545_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-12-26 01:08:03,937 INFO [localfetcher#1] o.a.h.m.task.reduce.LocalFetcher [LocalFetcher.java : 145] localfetcher#1 about to shuffle output of map attempt_local2015299545_0001_m_000000_0 decomp: 437 len: 441 to MEMORY
2021-12-26 01:08:03,946 INFO [localfetcher#1] o.a.h.m.t.reduce.InMemoryMapOutput [InMemoryMapOutput.java : 94] Read 437 bytes from map-output for attempt_local2015299545_0001_m_000000_0
2021-12-26 01:08:03,949 INFO [localfetcher#1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 323] closeInMemoryFile -> map-output of size: 437, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->437
2021-12-26 01:08:03,951 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 76] EventFetcher is interrupted.. Returning
2021-12-26 01:08:03,951 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:08:03,952 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 695] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-12-26 01:08:03,962 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:08:03,962 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:08:03,966 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 762] Merged 1 segments, 437 bytes to disk to satisfy reduce memory limit
2021-12-26 01:08:03,968 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 792] Merging 1 files, 441 bytes from disk
2021-12-26 01:08:03,969 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 807] Merging 0 segments, 0 bytes from memory into reduce
2021-12-26 01:08:03,969 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:08:03,971 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:08:03,972 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:08:04,242 INFO [pool-8-thread-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-12-26 01:08:04,640 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local2015299545_0001_r_000000_0 is done. And is in the process of committing
2021-12-26 01:08:04,642 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:08:04,642 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1409] Task attempt_local2015299545_0001_r_000000_0 is allowed to commit now
2021-12-26 01:08:04,776 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 598] Saved output of task 'attempt_local2015299545_0001_r_000000_0' to hdfs://localhost:9000/output/product
2021-12-26 01:08:04,777 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-26 01:08:04,777 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local2015299545_0001_r_000000_0' done.
2021-12-26 01:08:04,777 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local2015299545_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1102
		FILE: Number of bytes written=494973
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=14
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=31
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=635961344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:08:04,777 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 353] Finishing task: attempt_local2015299545_0001_r_000000_0
2021-12-26 01:08:04,777 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] reduce task executor complete.
2021-12-26 01:08:04,900 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 100%
2021-12-26 01:08:05,903 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1658] Job job_local2015299545_0001 completed successfully
2021-12-26 01:08:05,912 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 35
	File System Counters
		FILE: Number of bytes read=1290
		FILE: Number of bytes written=989505
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=580
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=62
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=208
		Total committed heap usage (bytes)=1271922688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:10:05,590 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 55] Starting HdfsApplication on DESKTOP-ORCB6UD with PID 26728 (C:\Users\UI\Desktop\bd-platform\springboot-hadoop\target\classes started by UI in C:\Users\UI\Desktop\bd-platform)
2021-12-26 01:10:05,594 INFO [main] com.bigdata.HdfsApplication [SpringApplication.java : 651] No active profile set, falling back to default profiles: default
2021-12-26 01:10:06,373 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 108] Tomcat initialized with port(s): 8080 (http)
2021-12-26 01:10:06,380 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Initializing ProtocolHandler ["http-nio-8080"]
2021-12-26 01:10:06,381 INFO [main] o.a.catalina.core.StandardService [DirectJDKLog.java : 173] Starting service [Tomcat]
2021-12-26 01:10:06,381 INFO [main] o.a.catalina.core.StandardEngine [DirectJDKLog.java : 173] Starting Servlet engine: [Apache Tomcat/9.0.39]
2021-12-26 01:10:06,480 INFO [main] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring embedded WebApplicationContext
2021-12-26 01:10:06,481 INFO [main] o.s.b.w.s.c.ServletWebServerApplicationContext [ServletWebServerApplicationContext.java : 285] Root WebApplicationContext: initialization completed in 837 ms
2021-12-26 01:10:06,641 INFO [main] o.s.s.c.ThreadPoolTaskExecutor [ExecutorConfigurationSupport.java : 181] Initializing ExecutorService 'applicationTaskExecutor'
2021-12-26 01:10:06,782 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Starting ProtocolHandler ["http-nio-8080"]
2021-12-26 01:10:06,802 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 220] Tomcat started on port(s): 8080 (http) with context path ''
2021-12-26 01:10:06,810 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 61] Started HdfsApplication in 1.645 seconds (JVM running for 3.003)
2021-12-26 01:12:14,422 INFO [http-nio-8080-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-12-26 01:12:14,422 INFO [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 525] Initializing Servlet 'dispatcherServlet'
2021-12-26 01:12:14,427 INFO [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 547] Completed initialization in 5 ms
2021-12-26 01:12:14,540 WARN [http-nio-8080-exec-2] org.apache.hadoop.util.Shell [Shell.java : 694] Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:549)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:570)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:593)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:690)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3533)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3528)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:216)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:213)
	at com.bigdata.hadoop.HdfsService.getFileSystem(HdfsService.java:156)
	at com.bigdata.hadoop.HdfsService.existFile(HdfsService.java:191)
	at com.bigdata.hadoop.MapReduceService.wordCount(MapReduceService.java:30)
	at com.bigdata.controller.MapReduceAction.wordCount(MapReduceAction.java:38)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:652)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:469)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517)
	... 65 common frames omitted
2021-12-26 01:12:15,502 INFO [http-nio-8080-exec-2] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 01:12:15,840 INFO [http-nio-8080-exec-2] o.a.c.b.FluentPropertyBeanIntrospector [FluentPropertyBeanIntrospector.java : 147] Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-12-26 01:12:15,851 WARN [http-nio-8080-exec-2] o.a.h.metrics2.impl.MetricsConfig [MetricsConfig.java : 134] Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 01:12:15,863 INFO [http-nio-8080-exec-2] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 374] Scheduled Metric snapshot period at 10 second(s).
2021-12-26 01:12:15,863 INFO [http-nio-8080-exec-2] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 191] JobTracker metrics system started
2021-12-26 01:12:16,312 WARN [http-nio-8080-exec-2] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 01:12:16,334 WARN [http-nio-8080-exec-2] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 01:12:16,356 INFO [http-nio-8080-exec-2] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 01:12:16,386 INFO [http-nio-8080-exec-2] o.a.h.m.l.i.CombineFileInputFormat [CombineFileInputFormat.java : 428] DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 290
2021-12-26 01:12:16,406 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 01:12:16,459 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local710038670_0001
2021-12-26 01:12:16,459 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 01:12:16,550 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 01:12:16,551 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local710038670_0001
2021-12-26 01:12:16,553 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 01:12:16,561 INFO [Thread-19] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:12:16,561 INFO [Thread-19] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:12:16,562 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 01:12:16,768 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 01:12:16,769 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local710038670_0001_m_000000_0
2021-12-26 01:12:16,789 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:12:16,789 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:12:16,794 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:12:16,795 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:12:16,801 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: Paths:/user/hadoop/test/product.txt:0+290
2021-12-26 01:12:16,818 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 01:12:16,818 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 01:12:16,818 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 01:12:16,818 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 01:12:16,818 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 01:12:16,822 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 01:12:17,039 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 
2021-12-26 01:12:17,040 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 01:12:17,040 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1498] Spilling map output
2021-12-26 01:12:17,040 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1499] bufstart = 0; bufend = 412; bufvoid = 104857600
2021-12-26 01:12:17,040 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1501] kvstart = 26214396(104857584); kvend = 26214260(104857040); length = 137/6553600
2021-12-26 01:12:17,054 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1696] Finished spill 0
2021-12-26 01:12:17,066 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local710038670_0001_m_000000_0 is done. And is in the process of committing
2021-12-26 01:12:17,069 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map
2021-12-26 01:12:17,069 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local710038670_0001_m_000000_0' done.
2021-12-26 01:12:17,073 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local710038670_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=188
		FILE: Number of bytes written=492124
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Spilled Records=31
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=329777152
	File Input Format Counters 
		Bytes Read=0
2021-12-26 01:12:17,073 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 277] Finishing task: attempt_local710038670_0001_m_000000_0
2021-12-26 01:12:17,074 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 01:12:17,075 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for reduce tasks
2021-12-26 01:12:17,075 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 330] Starting task: attempt_local710038670_0001_r_000000_0
2021-12-26 01:12:17,104 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:12:17,104 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:12:17,105 INFO [pool-8-thread-1] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:12:17,105 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:12:17,107 INFO [pool-8-thread-1] org.apache.hadoop.mapred.ReduceTask [ReduceTask.java : 363] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@cf5682c
2021-12-26 01:12:17,108 WARN [pool-8-thread-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 01:12:17,115 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 208] MergerManager: memoryLimit=2651586560, maxSingleShuffleLimit=662896640, mergeThreshold=1750047232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-12-26 01:12:17,117 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 61] attempt_local710038670_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-12-26 01:12:17,141 INFO [localfetcher#1] o.a.h.m.task.reduce.LocalFetcher [LocalFetcher.java : 145] localfetcher#1 about to shuffle output of map attempt_local710038670_0001_m_000000_0 decomp: 437 len: 441 to MEMORY
2021-12-26 01:12:17,146 INFO [localfetcher#1] o.a.h.m.t.reduce.InMemoryMapOutput [InMemoryMapOutput.java : 94] Read 437 bytes from map-output for attempt_local710038670_0001_m_000000_0
2021-12-26 01:12:17,147 INFO [localfetcher#1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 323] closeInMemoryFile -> map-output of size: 437, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->437
2021-12-26 01:12:17,148 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 76] EventFetcher is interrupted.. Returning
2021-12-26 01:12:17,149 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:12:17,149 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 695] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-12-26 01:12:17,156 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:12:17,157 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:12:17,159 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 762] Merged 1 segments, 437 bytes to disk to satisfy reduce memory limit
2021-12-26 01:12:17,160 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 792] Merging 1 files, 441 bytes from disk
2021-12-26 01:12:17,160 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 807] Merging 0 segments, 0 bytes from memory into reduce
2021-12-26 01:12:17,160 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:12:17,162 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:12:17,163 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:12:17,335 INFO [pool-8-thread-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-12-26 01:12:17,570 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local710038670_0001 running in uber mode : false
2021-12-26 01:12:17,572 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 0%
2021-12-26 01:12:17,712 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local710038670_0001_r_000000_0 is done. And is in the process of committing
2021-12-26 01:12:17,714 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:12:17,714 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1409] Task attempt_local710038670_0001_r_000000_0 is allowed to commit now
2021-12-26 01:12:17,850 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 598] Saved output of task 'attempt_local710038670_0001_r_000000_0' to hdfs://localhost:9000/output/product
2021-12-26 01:12:17,851 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-26 01:12:17,852 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local710038670_0001_r_000000_0' done.
2021-12-26 01:12:17,853 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local710038670_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1102
		FILE: Number of bytes written=492565
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=14
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=31
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=16
		Total committed heap usage (bytes)=490733568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:12:17,854 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 353] Finishing task: attempt_local710038670_0001_r_000000_0
2021-12-26 01:12:17,854 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] reduce task executor complete.
2021-12-26 01:12:18,584 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 100%
2021-12-26 01:12:18,586 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1658] Job job_local710038670_0001 completed successfully
2021-12-26 01:12:18,598 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 35
	File System Counters
		FILE: Number of bytes read=1290
		FILE: Number of bytes written=984689
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=580
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=62
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=16
		Total committed heap usage (bytes)=820510720
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:15:27,243 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 55] Starting HdfsApplication on DESKTOP-ORCB6UD with PID 27948 (C:\Users\UI\Desktop\bd-platform\springboot-hadoop\target\classes started by UI in C:\Users\UI\Desktop\bd-platform)
2021-12-26 01:15:27,251 INFO [main] com.bigdata.HdfsApplication [SpringApplication.java : 651] No active profile set, falling back to default profiles: default
2021-12-26 01:15:28,040 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 108] Tomcat initialized with port(s): 8080 (http)
2021-12-26 01:15:28,049 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Initializing ProtocolHandler ["http-nio-8080"]
2021-12-26 01:15:28,049 INFO [main] o.a.catalina.core.StandardService [DirectJDKLog.java : 173] Starting service [Tomcat]
2021-12-26 01:15:28,049 INFO [main] o.a.catalina.core.StandardEngine [DirectJDKLog.java : 173] Starting Servlet engine: [Apache Tomcat/9.0.39]
2021-12-26 01:15:28,152 INFO [main] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring embedded WebApplicationContext
2021-12-26 01:15:28,152 INFO [main] o.s.b.w.s.c.ServletWebServerApplicationContext [ServletWebServerApplicationContext.java : 285] Root WebApplicationContext: initialization completed in 840 ms
2021-12-26 01:15:28,313 INFO [main] o.s.s.c.ThreadPoolTaskExecutor [ExecutorConfigurationSupport.java : 181] Initializing ExecutorService 'applicationTaskExecutor'
2021-12-26 01:15:28,466 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Starting ProtocolHandler ["http-nio-8080"]
2021-12-26 01:15:28,488 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 220] Tomcat started on port(s): 8080 (http) with context path ''
2021-12-26 01:15:28,497 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 61] Started HdfsApplication in 1.843 seconds (JVM running for 3.097)
2021-12-26 01:15:40,012 INFO [http-nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-12-26 01:15:40,012 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 525] Initializing Servlet 'dispatcherServlet'
2021-12-26 01:15:40,017 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 547] Completed initialization in 5 ms
2021-12-26 01:15:40,120 WARN [http-nio-8080-exec-1] org.apache.hadoop.util.Shell [Shell.java : 694] Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:549)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:570)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:593)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:690)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3533)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3528)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:216)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:213)
	at com.bigdata.hadoop.HdfsService.getFileSystem(HdfsService.java:156)
	at com.bigdata.hadoop.HdfsService.existFile(HdfsService.java:191)
	at com.bigdata.hadoop.MapReduceService.wordCount(MapReduceService.java:30)
	at com.bigdata.controller.MapReduceAction.wordCount(MapReduceAction.java:38)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:652)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:469)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517)
	... 65 common frames omitted
2021-12-26 01:15:41,080 INFO [http-nio-8080-exec-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 01:15:41,414 INFO [http-nio-8080-exec-1] o.a.c.b.FluentPropertyBeanIntrospector [FluentPropertyBeanIntrospector.java : 147] Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-12-26 01:15:41,426 WARN [http-nio-8080-exec-1] o.a.h.metrics2.impl.MetricsConfig [MetricsConfig.java : 134] Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 01:15:41,439 INFO [http-nio-8080-exec-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 374] Scheduled Metric snapshot period at 10 second(s).
2021-12-26 01:15:41,439 INFO [http-nio-8080-exec-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 191] JobTracker metrics system started
2021-12-26 01:15:41,871 WARN [http-nio-8080-exec-1] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 01:15:41,900 WARN [http-nio-8080-exec-1] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 01:15:41,921 INFO [http-nio-8080-exec-1] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 01:15:41,951 INFO [http-nio-8080-exec-1] o.a.h.m.l.i.CombineFileInputFormat [CombineFileInputFormat.java : 428] DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 290
2021-12-26 01:15:41,972 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 01:15:42,025 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local944943690_0001
2021-12-26 01:15:42,025 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 01:15:42,116 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 01:15:42,117 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local944943690_0001
2021-12-26 01:15:42,119 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 01:15:42,128 INFO [Thread-19] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:15:42,128 INFO [Thread-19] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:15:42,129 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 01:15:42,317 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 01:15:42,318 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local944943690_0001_m_000000_0
2021-12-26 01:15:42,338 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:15:42,338 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:15:42,344 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:15:42,345 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:15:42,351 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: Paths:/user/hadoop/test/product.txt:0+290
2021-12-26 01:15:42,385 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 01:15:42,385 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 01:15:42,385 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 01:15:42,385 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 01:15:42,385 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 01:15:42,388 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 01:15:42,596 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 
2021-12-26 01:15:42,596 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 01:15:42,596 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1498] Spilling map output
2021-12-26 01:15:42,596 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1499] bufstart = 0; bufend = 412; bufvoid = 104857600
2021-12-26 01:15:42,596 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1501] kvstart = 26214396(104857584); kvend = 26214260(104857040); length = 137/6553600
2021-12-26 01:15:42,609 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1696] Finished spill 0
2021-12-26 01:15:42,621 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local944943690_0001_m_000000_0 is done. And is in the process of committing
2021-12-26 01:15:42,624 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map
2021-12-26 01:15:42,624 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local944943690_0001_m_000000_0' done.
2021-12-26 01:15:42,629 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local944943690_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=188
		FILE: Number of bytes written=492124
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Spilled Records=31
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=333971456
	File Input Format Counters 
		Bytes Read=0
2021-12-26 01:15:42,629 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 277] Finishing task: attempt_local944943690_0001_m_000000_0
2021-12-26 01:15:42,630 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 01:15:42,631 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for reduce tasks
2021-12-26 01:15:42,631 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 330] Starting task: attempt_local944943690_0001_r_000000_0
2021-12-26 01:15:42,640 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:15:42,640 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:15:42,640 INFO [pool-8-thread-1] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:15:42,640 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:15:42,643 INFO [pool-8-thread-1] org.apache.hadoop.mapred.ReduceTask [ReduceTask.java : 363] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@73f5e9bf
2021-12-26 01:15:42,644 WARN [pool-8-thread-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 01:15:42,651 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 208] MergerManager: memoryLimit=2651586560, maxSingleShuffleLimit=662896640, mergeThreshold=1750047232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-12-26 01:15:42,654 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 61] attempt_local944943690_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-12-26 01:15:42,677 INFO [localfetcher#1] o.a.h.m.task.reduce.LocalFetcher [LocalFetcher.java : 145] localfetcher#1 about to shuffle output of map attempt_local944943690_0001_m_000000_0 decomp: 437 len: 441 to MEMORY
2021-12-26 01:15:42,681 INFO [localfetcher#1] o.a.h.m.t.reduce.InMemoryMapOutput [InMemoryMapOutput.java : 94] Read 437 bytes from map-output for attempt_local944943690_0001_m_000000_0
2021-12-26 01:15:42,683 INFO [localfetcher#1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 323] closeInMemoryFile -> map-output of size: 437, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->437
2021-12-26 01:15:42,684 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 76] EventFetcher is interrupted.. Returning
2021-12-26 01:15:42,685 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:15:42,685 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 695] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-12-26 01:15:42,693 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:15:42,693 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:15:42,696 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 762] Merged 1 segments, 437 bytes to disk to satisfy reduce memory limit
2021-12-26 01:15:42,696 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 792] Merging 1 files, 441 bytes from disk
2021-12-26 01:15:42,697 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 807] Merging 0 segments, 0 bytes from memory into reduce
2021-12-26 01:15:42,697 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:15:42,699 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:15:42,699 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:15:42,877 INFO [pool-8-thread-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-12-26 01:15:43,127 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local944943690_0001 running in uber mode : false
2021-12-26 01:15:43,132 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 0%
2021-12-26 01:15:43,432 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local944943690_0001_r_000000_0 is done. And is in the process of committing
2021-12-26 01:15:43,434 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:15:43,434 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1409] Task attempt_local944943690_0001_r_000000_0 is allowed to commit now
2021-12-26 01:15:43,568 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 598] Saved output of task 'attempt_local944943690_0001_r_000000_0' to hdfs://localhost:9000/output/product
2021-12-26 01:15:43,568 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-26 01:15:43,568 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local944943690_0001_r_000000_0' done.
2021-12-26 01:15:43,569 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local944943690_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1102
		FILE: Number of bytes written=492565
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=14
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=31
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=18
		Total committed heap usage (bytes)=509607936
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:15:43,569 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 353] Finishing task: attempt_local944943690_0001_r_000000_0
2021-12-26 01:15:43,569 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] reduce task executor complete.
2021-12-26 01:15:44,137 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 100%
2021-12-26 01:15:44,138 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1658] Job job_local944943690_0001 completed successfully
2021-12-26 01:15:44,152 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 35
	File System Counters
		FILE: Number of bytes read=1290
		FILE: Number of bytes written=984689
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=580
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=62
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=28
		Total committed heap usage (bytes)=843579392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:18:19,656 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 55] Starting HdfsApplication on DESKTOP-ORCB6UD with PID 22500 (C:\Users\UI\Desktop\bd-platform\springboot-hadoop\target\classes started by UI in C:\Users\UI\Desktop\bd-platform)
2021-12-26 01:18:19,663 INFO [main] com.bigdata.HdfsApplication [SpringApplication.java : 651] No active profile set, falling back to default profiles: default
2021-12-26 01:18:21,205 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 108] Tomcat initialized with port(s): 8080 (http)
2021-12-26 01:18:21,221 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Initializing ProtocolHandler ["http-nio-8080"]
2021-12-26 01:18:21,222 INFO [main] o.a.catalina.core.StandardService [DirectJDKLog.java : 173] Starting service [Tomcat]
2021-12-26 01:18:21,222 INFO [main] o.a.catalina.core.StandardEngine [DirectJDKLog.java : 173] Starting Servlet engine: [Apache Tomcat/9.0.39]
2021-12-26 01:18:21,405 INFO [main] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring embedded WebApplicationContext
2021-12-26 01:18:21,405 INFO [main] o.s.b.w.s.c.ServletWebServerApplicationContext [ServletWebServerApplicationContext.java : 285] Root WebApplicationContext: initialization completed in 1599 ms
2021-12-26 01:18:21,668 INFO [main] o.s.s.c.ThreadPoolTaskExecutor [ExecutorConfigurationSupport.java : 181] Initializing ExecutorService 'applicationTaskExecutor'
2021-12-26 01:18:21,849 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Starting ProtocolHandler ["http-nio-8080"]
2021-12-26 01:18:21,874 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 220] Tomcat started on port(s): 8080 (http) with context path ''
2021-12-26 01:18:21,885 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 61] Started HdfsApplication in 2.859 seconds (JVM running for 5.538)
2021-12-26 01:18:55,364 INFO [http-nio-8080-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-12-26 01:18:55,365 INFO [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 525] Initializing Servlet 'dispatcherServlet'
2021-12-26 01:18:55,373 INFO [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 547] Completed initialization in 8 ms
2021-12-26 01:18:55,528 WARN [http-nio-8080-exec-2] org.apache.hadoop.util.Shell [Shell.java : 694] Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:549)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:570)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:593)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:690)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3533)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3528)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:216)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:213)
	at com.bigdata.hadoop.HdfsService.getFileSystem(HdfsService.java:156)
	at com.bigdata.hadoop.HdfsService.existFile(HdfsService.java:191)
	at com.bigdata.hadoop.MapReduceService.wordCount(MapReduceService.java:30)
	at com.bigdata.controller.MapReduceAction.wordCount(MapReduceAction.java:38)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:652)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:469)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517)
	... 65 common frames omitted
2021-12-26 01:18:56,788 INFO [http-nio-8080-exec-2] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 01:18:57,135 INFO [http-nio-8080-exec-2] o.a.c.b.FluentPropertyBeanIntrospector [FluentPropertyBeanIntrospector.java : 147] Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-12-26 01:18:57,160 WARN [http-nio-8080-exec-2] o.a.h.metrics2.impl.MetricsConfig [MetricsConfig.java : 134] Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 01:18:57,181 INFO [http-nio-8080-exec-2] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 374] Scheduled Metric snapshot period at 10 second(s).
2021-12-26 01:18:57,182 INFO [http-nio-8080-exec-2] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 191] JobTracker metrics system started
2021-12-26 01:18:57,780 WARN [http-nio-8080-exec-2] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 01:18:57,818 WARN [http-nio-8080-exec-2] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 01:18:57,856 INFO [http-nio-8080-exec-2] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 01:18:57,907 INFO [http-nio-8080-exec-2] o.a.h.m.l.i.CombineFileInputFormat [CombineFileInputFormat.java : 428] DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 290
2021-12-26 01:18:57,944 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 01:18:58,041 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local58086308_0001
2021-12-26 01:18:58,041 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 01:18:58,223 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 01:18:58,224 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local58086308_0001
2021-12-26 01:18:58,227 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 01:18:58,238 INFO [Thread-21] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:18:58,238 INFO [Thread-21] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:18:58,240 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 01:18:58,544 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 01:18:58,545 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local58086308_0001_m_000000_0
2021-12-26 01:18:58,569 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:18:58,570 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:18:58,575 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:18:58,575 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:18:58,589 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: Paths:/user/hadoop/test/product.txt:0+290
2021-12-26 01:18:58,612 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 01:18:58,612 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 01:18:58,612 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 01:18:58,612 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 01:18:58,612 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 01:18:58,618 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 01:18:59,233 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local58086308_0001 running in uber mode : false
2021-12-26 01:18:59,240 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 0% reduce 0%
2021-12-26 01:18:59,284 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 
2021-12-26 01:18:59,284 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 01:18:59,284 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1498] Spilling map output
2021-12-26 01:18:59,285 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1499] bufstart = 0; bufend = 412; bufvoid = 104857600
2021-12-26 01:18:59,285 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1501] kvstart = 26214396(104857584); kvend = 26214260(104857040); length = 137/6553600
2021-12-26 01:18:59,308 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1696] Finished spill 0
2021-12-26 01:18:59,327 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local58086308_0001_m_000000_0 is done. And is in the process of committing
2021-12-26 01:18:59,331 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map
2021-12-26 01:18:59,332 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local58086308_0001_m_000000_0' done.
2021-12-26 01:18:59,336 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local58086308_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=188
		FILE: Number of bytes written=489716
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Spilled Records=31
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=341
		Total committed heap usage (bytes)=621805568
	File Input Format Counters 
		Bytes Read=0
2021-12-26 01:18:59,337 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 277] Finishing task: attempt_local58086308_0001_m_000000_0
2021-12-26 01:18:59,337 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 01:18:59,339 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for reduce tasks
2021-12-26 01:18:59,340 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 330] Starting task: attempt_local58086308_0001_r_000000_0
2021-12-26 01:18:59,351 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:18:59,351 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:18:59,352 INFO [pool-8-thread-1] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:18:59,352 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:18:59,354 INFO [pool-8-thread-1] org.apache.hadoop.mapred.ReduceTask [ReduceTask.java : 363] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7d7a4c09
2021-12-26 01:18:59,356 WARN [pool-8-thread-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 01:18:59,366 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 208] MergerManager: memoryLimit=2651586560, maxSingleShuffleLimit=662896640, mergeThreshold=1750047232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-12-26 01:18:59,370 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 61] attempt_local58086308_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-12-26 01:18:59,402 INFO [localfetcher#1] o.a.h.m.task.reduce.LocalFetcher [LocalFetcher.java : 145] localfetcher#1 about to shuffle output of map attempt_local58086308_0001_m_000000_0 decomp: 437 len: 441 to MEMORY
2021-12-26 01:18:59,407 INFO [localfetcher#1] o.a.h.m.t.reduce.InMemoryMapOutput [InMemoryMapOutput.java : 94] Read 437 bytes from map-output for attempt_local58086308_0001_m_000000_0
2021-12-26 01:18:59,409 INFO [localfetcher#1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 323] closeInMemoryFile -> map-output of size: 437, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->437
2021-12-26 01:18:59,411 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 76] EventFetcher is interrupted.. Returning
2021-12-26 01:18:59,412 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:18:59,413 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 695] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-12-26 01:18:59,423 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:18:59,423 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:18:59,426 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 762] Merged 1 segments, 437 bytes to disk to satisfy reduce memory limit
2021-12-26 01:18:59,427 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 792] Merging 1 files, 441 bytes from disk
2021-12-26 01:18:59,428 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 807] Merging 0 segments, 0 bytes from memory into reduce
2021-12-26 01:18:59,428 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:18:59,432 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:18:59,432 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:18:59,606 INFO [pool-8-thread-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-12-26 01:19:00,113 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local58086308_0001_r_000000_0 is done. And is in the process of committing
2021-12-26 01:19:00,117 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:19:00,117 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1409] Task attempt_local58086308_0001_r_000000_0 is allowed to commit now
2021-12-26 01:19:00,244 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 0%
2021-12-26 01:19:00,292 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 598] Saved output of task 'attempt_local58086308_0001_r_000000_0' to hdfs://localhost:9000/output/product
2021-12-26 01:19:00,292 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-26 01:19:00,293 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local58086308_0001_r_000000_0' done.
2021-12-26 01:19:00,293 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local58086308_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1102
		FILE: Number of bytes written=490157
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=14
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=31
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=621805568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:19:00,293 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 353] Finishing task: attempt_local58086308_0001_r_000000_0
2021-12-26 01:19:00,293 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] reduce task executor complete.
2021-12-26 01:19:01,254 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 100%
2021-12-26 01:19:01,254 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1658] Job job_local58086308_0001 completed successfully
2021-12-26 01:19:01,263 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 35
	File System Counters
		FILE: Number of bytes read=1290
		FILE: Number of bytes written=979873
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=580
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=62
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=341
		Total committed heap usage (bytes)=1243611136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:20:37,551 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 55] Starting HdfsApplication on DESKTOP-ORCB6UD with PID 26740 (C:\Users\UI\Desktop\bd-platform\springboot-hadoop\target\classes started by UI in C:\Users\UI\Desktop\bd-platform)
2021-12-26 01:20:37,558 INFO [main] com.bigdata.HdfsApplication [SpringApplication.java : 651] No active profile set, falling back to default profiles: default
2021-12-26 01:20:38,963 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 108] Tomcat initialized with port(s): 8080 (http)
2021-12-26 01:20:38,979 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Initializing ProtocolHandler ["http-nio-8080"]
2021-12-26 01:20:38,980 INFO [main] o.a.catalina.core.StandardService [DirectJDKLog.java : 173] Starting service [Tomcat]
2021-12-26 01:20:38,981 INFO [main] o.a.catalina.core.StandardEngine [DirectJDKLog.java : 173] Starting Servlet engine: [Apache Tomcat/9.0.39]
2021-12-26 01:20:39,178 INFO [main] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring embedded WebApplicationContext
2021-12-26 01:20:39,178 INFO [main] o.s.b.w.s.c.ServletWebServerApplicationContext [ServletWebServerApplicationContext.java : 285] Root WebApplicationContext: initialization completed in 1545 ms
2021-12-26 01:20:39,482 INFO [main] o.s.s.c.ThreadPoolTaskExecutor [ExecutorConfigurationSupport.java : 181] Initializing ExecutorService 'applicationTaskExecutor'
2021-12-26 01:20:39,776 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Starting ProtocolHandler ["http-nio-8080"]
2021-12-26 01:20:39,818 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 220] Tomcat started on port(s): 8080 (http) with context path ''
2021-12-26 01:20:39,831 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 61] Started HdfsApplication in 2.991 seconds (JVM running for 5.412)
2021-12-26 01:20:55,636 INFO [http-nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-12-26 01:20:55,637 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 525] Initializing Servlet 'dispatcherServlet'
2021-12-26 01:20:55,641 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 547] Completed initialization in 4 ms
2021-12-26 01:20:55,749 WARN [http-nio-8080-exec-1] org.apache.hadoop.util.Shell [Shell.java : 694] Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:549)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:570)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:593)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:690)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3533)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3528)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:216)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:213)
	at com.bigdata.hadoop.HdfsService.getFileSystem(HdfsService.java:156)
	at com.bigdata.hadoop.HdfsService.existFile(HdfsService.java:191)
	at com.bigdata.hadoop.MapReduceService.wordCount(MapReduceService.java:30)
	at com.bigdata.controller.MapReduceAction.wordCount(MapReduceAction.java:38)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:652)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:469)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517)
	... 65 common frames omitted
2021-12-26 01:20:56,953 INFO [http-nio-8080-exec-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 01:20:57,233 INFO [http-nio-8080-exec-1] o.a.c.b.FluentPropertyBeanIntrospector [FluentPropertyBeanIntrospector.java : 147] Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-12-26 01:20:57,247 WARN [http-nio-8080-exec-1] o.a.h.metrics2.impl.MetricsConfig [MetricsConfig.java : 134] Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 01:20:57,273 INFO [http-nio-8080-exec-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 374] Scheduled Metric snapshot period at 10 second(s).
2021-12-26 01:20:57,273 INFO [http-nio-8080-exec-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 191] JobTracker metrics system started
2021-12-26 01:20:57,875 WARN [http-nio-8080-exec-1] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 01:20:57,896 WARN [http-nio-8080-exec-1] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 01:20:57,927 INFO [http-nio-8080-exec-1] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 01:20:57,964 INFO [http-nio-8080-exec-1] o.a.h.m.l.i.CombineFileInputFormat [CombineFileInputFormat.java : 428] DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 290
2021-12-26 01:20:57,992 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 01:20:58,049 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local162654096_0001
2021-12-26 01:20:58,049 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 01:20:58,161 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 01:20:58,162 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local162654096_0001
2021-12-26 01:20:58,164 INFO [Thread-22] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 01:20:58,176 INFO [Thread-22] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:20:58,176 INFO [Thread-22] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:20:58,177 INFO [Thread-22] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 01:20:58,449 INFO [Thread-22] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 01:20:58,450 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local162654096_0001_m_000000_0
2021-12-26 01:20:58,474 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:20:58,474 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:20:58,480 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:20:58,481 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:20:58,501 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: Paths:/user/hadoop/test/product.txt:0+290
2021-12-26 01:20:58,543 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 01:20:58,543 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 01:20:58,543 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 01:20:58,543 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 01:20:58,543 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 01:20:58,546 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 01:20:58,800 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 
2021-12-26 01:20:58,801 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 01:20:58,801 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1498] Spilling map output
2021-12-26 01:20:58,801 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1499] bufstart = 0; bufend = 412; bufvoid = 104857600
2021-12-26 01:20:58,801 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1501] kvstart = 26214396(104857584); kvend = 26214260(104857040); length = 137/6553600
2021-12-26 01:20:58,815 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1696] Finished spill 0
2021-12-26 01:20:58,829 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local162654096_0001_m_000000_0 is done. And is in the process of committing
2021-12-26 01:20:58,832 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map
2021-12-26 01:20:58,832 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local162654096_0001_m_000000_0' done.
2021-12-26 01:20:58,838 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local162654096_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=188
		FILE: Number of bytes written=492124
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Spilled Records=31
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=502792192
	File Input Format Counters 
		Bytes Read=0
2021-12-26 01:20:58,838 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 277] Finishing task: attempt_local162654096_0001_m_000000_0
2021-12-26 01:20:58,839 INFO [Thread-22] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 01:20:58,840 INFO [Thread-22] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for reduce tasks
2021-12-26 01:20:58,840 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 330] Starting task: attempt_local162654096_0001_r_000000_0
2021-12-26 01:20:58,848 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:20:58,849 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:20:58,849 INFO [pool-8-thread-1] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:20:58,849 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:20:58,851 INFO [pool-8-thread-1] org.apache.hadoop.mapred.ReduceTask [ReduceTask.java : 363] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5b8e92de
2021-12-26 01:20:58,853 WARN [pool-8-thread-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 01:20:58,860 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 208] MergerManager: memoryLimit=2651586560, maxSingleShuffleLimit=662896640, mergeThreshold=1750047232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-12-26 01:20:58,863 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 61] attempt_local162654096_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-12-26 01:20:58,891 INFO [localfetcher#1] o.a.h.m.task.reduce.LocalFetcher [LocalFetcher.java : 145] localfetcher#1 about to shuffle output of map attempt_local162654096_0001_m_000000_0 decomp: 437 len: 441 to MEMORY
2021-12-26 01:20:58,895 INFO [localfetcher#1] o.a.h.m.t.reduce.InMemoryMapOutput [InMemoryMapOutput.java : 94] Read 437 bytes from map-output for attempt_local162654096_0001_m_000000_0
2021-12-26 01:20:58,897 INFO [localfetcher#1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 323] closeInMemoryFile -> map-output of size: 437, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->437
2021-12-26 01:20:58,899 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 76] EventFetcher is interrupted.. Returning
2021-12-26 01:20:58,900 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:20:58,900 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 695] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-12-26 01:20:58,908 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:20:58,908 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:20:58,911 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 762] Merged 1 segments, 437 bytes to disk to satisfy reduce memory limit
2021-12-26 01:20:58,912 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 792] Merging 1 files, 441 bytes from disk
2021-12-26 01:20:58,912 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 807] Merging 0 segments, 0 bytes from memory into reduce
2021-12-26 01:20:58,913 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:20:58,916 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:20:58,916 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:20:59,095 INFO [pool-8-thread-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-12-26 01:20:59,185 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local162654096_0001 running in uber mode : false
2021-12-26 01:20:59,186 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 0%
2021-12-26 01:20:59,523 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local162654096_0001_r_000000_0 is done. And is in the process of committing
2021-12-26 01:20:59,525 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:20:59,525 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1409] Task attempt_local162654096_0001_r_000000_0 is allowed to commit now
2021-12-26 01:20:59,769 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 598] Saved output of task 'attempt_local162654096_0001_r_000000_0' to hdfs://localhost:9000/output/product
2021-12-26 01:20:59,769 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-26 01:20:59,770 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local162654096_0001_r_000000_0' done.
2021-12-26 01:20:59,770 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local162654096_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1102
		FILE: Number of bytes written=492565
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=14
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=31
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=502792192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:20:59,770 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 353] Finishing task: attempt_local162654096_0001_r_000000_0
2021-12-26 01:20:59,770 INFO [Thread-22] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] reduce task executor complete.
2021-12-26 01:21:00,194 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 100%
2021-12-26 01:21:00,194 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1658] Job job_local162654096_0001 completed successfully
2021-12-26 01:21:00,204 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 35
	File System Counters
		FILE: Number of bytes read=1290
		FILE: Number of bytes written=984689
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=580
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=62
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=1005584384
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:28:01,090 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 55] Starting HdfsApplication on DESKTOP-ORCB6UD with PID 26816 (C:\Users\UI\Desktop\bd-platform\springboot-hadoop\target\classes started by UI in C:\Users\UI\Desktop\bd-platform)
2021-12-26 01:28:01,095 INFO [main] com.bigdata.HdfsApplication [SpringApplication.java : 651] No active profile set, falling back to default profiles: default
2021-12-26 01:28:02,196 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 108] Tomcat initialized with port(s): 8080 (http)
2021-12-26 01:28:02,204 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Initializing ProtocolHandler ["http-nio-8080"]
2021-12-26 01:28:02,205 INFO [main] o.a.catalina.core.StandardService [DirectJDKLog.java : 173] Starting service [Tomcat]
2021-12-26 01:28:02,205 INFO [main] o.a.catalina.core.StandardEngine [DirectJDKLog.java : 173] Starting Servlet engine: [Apache Tomcat/9.0.39]
2021-12-26 01:28:02,294 INFO [main] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring embedded WebApplicationContext
2021-12-26 01:28:02,294 INFO [main] o.s.b.w.s.c.ServletWebServerApplicationContext [ServletWebServerApplicationContext.java : 285] Root WebApplicationContext: initialization completed in 1155 ms
2021-12-26 01:28:02,440 INFO [main] o.s.s.c.ThreadPoolTaskExecutor [ExecutorConfigurationSupport.java : 181] Initializing ExecutorService 'applicationTaskExecutor'
2021-12-26 01:28:02,574 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Starting ProtocolHandler ["http-nio-8080"]
2021-12-26 01:28:02,594 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 220] Tomcat started on port(s): 8080 (http) with context path ''
2021-12-26 01:28:02,601 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 61] Started HdfsApplication in 1.863 seconds (JVM running for 3.185)
2021-12-26 01:28:23,192 INFO [http-nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-12-26 01:28:23,193 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 525] Initializing Servlet 'dispatcherServlet'
2021-12-26 01:28:23,197 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 547] Completed initialization in 4 ms
2021-12-26 01:28:23,306 WARN [http-nio-8080-exec-1] org.apache.hadoop.util.Shell [Shell.java : 694] Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:549)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:570)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:593)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:690)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3533)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3528)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:216)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:213)
	at com.bigdata.hadoop.HdfsService.getFileSystem(HdfsService.java:156)
	at com.bigdata.hadoop.HdfsService.existFile(HdfsService.java:191)
	at com.bigdata.hadoop.MapReduceService.wordCount(MapReduceService.java:30)
	at com.bigdata.controller.MapReduceAction.wordCount(MapReduceAction.java:38)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:652)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:469)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517)
	... 65 common frames omitted
2021-12-26 01:28:24,184 INFO [http-nio-8080-exec-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 01:28:24,481 INFO [http-nio-8080-exec-1] o.a.c.b.FluentPropertyBeanIntrospector [FluentPropertyBeanIntrospector.java : 147] Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-12-26 01:28:24,494 WARN [http-nio-8080-exec-1] o.a.h.metrics2.impl.MetricsConfig [MetricsConfig.java : 134] Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 01:28:24,506 INFO [http-nio-8080-exec-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 374] Scheduled Metric snapshot period at 10 second(s).
2021-12-26 01:28:24,507 INFO [http-nio-8080-exec-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 191] JobTracker metrics system started
2021-12-26 01:28:25,000 WARN [http-nio-8080-exec-1] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 01:28:25,016 WARN [http-nio-8080-exec-1] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 01:28:25,039 INFO [http-nio-8080-exec-1] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 01:28:25,086 INFO [http-nio-8080-exec-1] o.a.h.m.l.i.CombineFileInputFormat [CombineFileInputFormat.java : 428] DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 290
2021-12-26 01:28:25,106 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 01:28:25,153 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local39704686_0001
2021-12-26 01:28:25,153 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 01:28:25,237 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 01:28:25,238 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local39704686_0001
2021-12-26 01:28:25,240 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 01:28:25,247 INFO [Thread-19] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:28:25,247 INFO [Thread-19] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:28:25,248 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 01:28:25,447 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 01:28:25,448 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local39704686_0001_m_000000_0
2021-12-26 01:28:25,469 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:28:25,470 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:28:25,474 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:28:25,475 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:28:25,490 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: Paths:/user/hadoop/test/product.txt:0+290
2021-12-26 01:28:25,540 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 01:28:25,541 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 01:28:25,541 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 01:28:25,541 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 01:28:25,541 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 01:28:25,544 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 01:28:25,759 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 
2021-12-26 01:28:25,759 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 01:28:25,759 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1498] Spilling map output
2021-12-26 01:28:25,760 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1499] bufstart = 0; bufend = 412; bufvoid = 104857600
2021-12-26 01:28:25,760 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1501] kvstart = 26214396(104857584); kvend = 26214260(104857040); length = 137/6553600
2021-12-26 01:28:25,773 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1696] Finished spill 0
2021-12-26 01:28:25,785 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local39704686_0001_m_000000_0 is done. And is in the process of committing
2021-12-26 01:28:25,788 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map
2021-12-26 01:28:25,788 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local39704686_0001_m_000000_0' done.
2021-12-26 01:28:25,792 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local39704686_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=188
		FILE: Number of bytes written=489716
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Spilled Records=31
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=309329920
	File Input Format Counters 
		Bytes Read=0
2021-12-26 01:28:25,792 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 277] Finishing task: attempt_local39704686_0001_m_000000_0
2021-12-26 01:28:25,793 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 01:28:25,795 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for reduce tasks
2021-12-26 01:28:25,795 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 330] Starting task: attempt_local39704686_0001_r_000000_0
2021-12-26 01:28:25,803 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:28:25,803 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:28:25,803 INFO [pool-8-thread-1] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:28:25,804 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:28:25,805 INFO [pool-8-thread-1] org.apache.hadoop.mapred.ReduceTask [ReduceTask.java : 363] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@171a40cc
2021-12-26 01:28:25,806 WARN [pool-8-thread-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 01:28:25,814 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 208] MergerManager: memoryLimit=2651586560, maxSingleShuffleLimit=662896640, mergeThreshold=1750047232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-12-26 01:28:25,816 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 61] attempt_local39704686_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-12-26 01:28:25,839 INFO [localfetcher#1] o.a.h.m.task.reduce.LocalFetcher [LocalFetcher.java : 145] localfetcher#1 about to shuffle output of map attempt_local39704686_0001_m_000000_0 decomp: 437 len: 441 to MEMORY
2021-12-26 01:28:25,849 INFO [localfetcher#1] o.a.h.m.t.reduce.InMemoryMapOutput [InMemoryMapOutput.java : 94] Read 437 bytes from map-output for attempt_local39704686_0001_m_000000_0
2021-12-26 01:28:25,851 INFO [localfetcher#1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 323] closeInMemoryFile -> map-output of size: 437, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->437
2021-12-26 01:28:25,852 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 76] EventFetcher is interrupted.. Returning
2021-12-26 01:28:25,852 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:28:25,853 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 695] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-12-26 01:28:26,040 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:28:26,041 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:28:26,044 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 762] Merged 1 segments, 437 bytes to disk to satisfy reduce memory limit
2021-12-26 01:28:26,044 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 792] Merging 1 files, 441 bytes from disk
2021-12-26 01:28:26,045 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 807] Merging 0 segments, 0 bytes from memory into reduce
2021-12-26 01:28:26,045 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:28:26,047 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:28:26,047 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:28:26,253 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local39704686_0001 running in uber mode : false
2021-12-26 01:28:26,254 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 0%
2021-12-26 01:28:26,353 INFO [pool-8-thread-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-12-26 01:28:26,842 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local39704686_0001_r_000000_0 is done. And is in the process of committing
2021-12-26 01:28:26,844 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:28:26,844 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1409] Task attempt_local39704686_0001_r_000000_0 is allowed to commit now
2021-12-26 01:28:27,045 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 598] Saved output of task 'attempt_local39704686_0001_r_000000_0' to hdfs://localhost:9000/output/product
2021-12-26 01:28:27,046 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-26 01:28:27,047 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local39704686_0001_r_000000_0' done.
2021-12-26 01:28:27,048 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local39704686_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1102
		FILE: Number of bytes written=490157
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=14
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=31
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=171
		Total committed heap usage (bytes)=493355008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:28:27,048 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 353] Finishing task: attempt_local39704686_0001_r_000000_0
2021-12-26 01:28:27,049 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] reduce task executor complete.
2021-12-26 01:28:27,265 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 100%
2021-12-26 01:28:28,271 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1658] Job job_local39704686_0001 completed successfully
2021-12-26 01:28:28,279 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 35
	File System Counters
		FILE: Number of bytes read=1290
		FILE: Number of bytes written=979873
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=580
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=62
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=171
		Total committed heap usage (bytes)=802684928
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:29:42,751 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 55] Starting HdfsApplication on DESKTOP-ORCB6UD with PID 32232 (C:\Users\UI\Desktop\bd-platform\springboot-hadoop\target\classes started by UI in C:\Users\UI\Desktop\bd-platform)
2021-12-26 01:29:42,754 INFO [main] com.bigdata.HdfsApplication [SpringApplication.java : 651] No active profile set, falling back to default profiles: default
2021-12-26 01:29:43,645 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 108] Tomcat initialized with port(s): 8080 (http)
2021-12-26 01:29:43,653 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Initializing ProtocolHandler ["http-nio-8080"]
2021-12-26 01:29:43,653 INFO [main] o.a.catalina.core.StandardService [DirectJDKLog.java : 173] Starting service [Tomcat]
2021-12-26 01:29:43,654 INFO [main] o.a.catalina.core.StandardEngine [DirectJDKLog.java : 173] Starting Servlet engine: [Apache Tomcat/9.0.39]
2021-12-26 01:29:43,751 INFO [main] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring embedded WebApplicationContext
2021-12-26 01:29:43,751 INFO [main] o.s.b.w.s.c.ServletWebServerApplicationContext [ServletWebServerApplicationContext.java : 285] Root WebApplicationContext: initialization completed in 943 ms
2021-12-26 01:29:43,929 INFO [main] o.s.s.c.ThreadPoolTaskExecutor [ExecutorConfigurationSupport.java : 181] Initializing ExecutorService 'applicationTaskExecutor'
2021-12-26 01:29:44,078 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Starting ProtocolHandler ["http-nio-8080"]
2021-12-26 01:29:44,098 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 220] Tomcat started on port(s): 8080 (http) with context path ''
2021-12-26 01:29:44,106 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 61] Started HdfsApplication in 1.668 seconds (JVM running for 2.977)
2021-12-26 01:30:23,032 INFO [http-nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-12-26 01:30:23,032 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 525] Initializing Servlet 'dispatcherServlet'
2021-12-26 01:30:23,036 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 547] Completed initialization in 4 ms
2021-12-26 01:30:23,053 WARN [http-nio-8080-exec-1] o.s.w.s.m.s.DefaultHandlerExceptionResolver [AbstractHandlerExceptionResolver.java : 199] Resolved [org.springframework.web.HttpRequestMethodNotSupportedException: Request method 'GET' not supported]
2021-12-26 01:30:27,309 INFO [http-nio-8080-exec-3] c.bigdata.controller.MapReduceAction [MapReduceAction.java : 71] ======================================================
2021-12-26 01:30:46,871 WARN [http-nio-8080-exec-4] org.apache.hadoop.util.Shell [Shell.java : 694] Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:549)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:570)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:593)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:690)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3533)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3528)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:216)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:213)
	at com.bigdata.hadoop.HdfsService.getFileSystem(HdfsService.java:156)
	at com.bigdata.hadoop.HdfsService.existFile(HdfsService.java:191)
	at com.bigdata.hadoop.MapReduceService.wordCount(MapReduceService.java:30)
	at com.bigdata.controller.MapReduceAction.wordCount(MapReduceAction.java:38)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:652)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:469)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517)
	... 65 common frames omitted
2021-12-26 01:30:47,742 INFO [http-nio-8080-exec-4] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 01:30:48,086 INFO [http-nio-8080-exec-4] o.a.c.b.FluentPropertyBeanIntrospector [FluentPropertyBeanIntrospector.java : 147] Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-12-26 01:30:48,097 WARN [http-nio-8080-exec-4] o.a.h.metrics2.impl.MetricsConfig [MetricsConfig.java : 134] Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 01:30:48,109 INFO [http-nio-8080-exec-4] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 374] Scheduled Metric snapshot period at 10 second(s).
2021-12-26 01:30:48,109 INFO [http-nio-8080-exec-4] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 191] JobTracker metrics system started
2021-12-26 01:30:48,568 WARN [http-nio-8080-exec-4] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 01:30:48,580 WARN [http-nio-8080-exec-4] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 01:30:48,601 INFO [http-nio-8080-exec-4] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 01:30:48,627 INFO [http-nio-8080-exec-4] o.a.h.m.l.i.CombineFileInputFormat [CombineFileInputFormat.java : 428] DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 290
2021-12-26 01:30:48,649 INFO [http-nio-8080-exec-4] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 01:30:48,697 INFO [http-nio-8080-exec-4] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local1626972315_0001
2021-12-26 01:30:48,697 INFO [http-nio-8080-exec-4] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 01:30:48,783 INFO [http-nio-8080-exec-4] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 01:30:48,784 INFO [http-nio-8080-exec-4] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local1626972315_0001
2021-12-26 01:30:48,787 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 01:30:48,793 INFO [Thread-19] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:30:48,793 INFO [Thread-19] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:30:48,794 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 01:30:49,019 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 01:30:49,020 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local1626972315_0001_m_000000_0
2021-12-26 01:30:49,039 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:30:49,039 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:30:49,044 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:30:49,046 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:30:49,053 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: Paths:/user/hadoop/test/product.txt:0+290
2021-12-26 01:30:49,108 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 01:30:49,109 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 01:30:49,109 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 01:30:49,109 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 01:30:49,109 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 01:30:49,112 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 01:30:49,628 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 
2021-12-26 01:30:49,629 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 01:30:49,629 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1498] Spilling map output
2021-12-26 01:30:49,629 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1499] bufstart = 0; bufend = 412; bufvoid = 104857600
2021-12-26 01:30:49,629 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1501] kvstart = 26214396(104857584); kvend = 26214260(104857040); length = 137/6553600
2021-12-26 01:30:49,642 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1696] Finished spill 0
2021-12-26 01:30:49,655 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local1626972315_0001_m_000000_0 is done. And is in the process of committing
2021-12-26 01:30:49,658 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map
2021-12-26 01:30:49,658 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local1626972315_0001_m_000000_0' done.
2021-12-26 01:30:49,662 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local1626972315_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=188
		FILE: Number of bytes written=494532
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Spilled Records=31
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=285
		Total committed heap usage (bytes)=607125504
	File Input Format Counters 
		Bytes Read=0
2021-12-26 01:30:49,663 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 277] Finishing task: attempt_local1626972315_0001_m_000000_0
2021-12-26 01:30:49,664 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 01:30:49,666 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for reduce tasks
2021-12-26 01:30:49,666 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 330] Starting task: attempt_local1626972315_0001_r_000000_0
2021-12-26 01:30:49,675 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:30:49,676 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:30:49,676 INFO [pool-8-thread-1] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:30:49,676 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:30:49,677 INFO [pool-8-thread-1] org.apache.hadoop.mapred.ReduceTask [ReduceTask.java : 363] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3dff998f
2021-12-26 01:30:49,680 WARN [pool-8-thread-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 01:30:49,688 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 208] MergerManager: memoryLimit=2651586560, maxSingleShuffleLimit=662896640, mergeThreshold=1750047232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-12-26 01:30:49,690 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 61] attempt_local1626972315_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-12-26 01:30:49,712 INFO [localfetcher#1] o.a.h.m.task.reduce.LocalFetcher [LocalFetcher.java : 145] localfetcher#1 about to shuffle output of map attempt_local1626972315_0001_m_000000_0 decomp: 437 len: 441 to MEMORY
2021-12-26 01:30:49,717 INFO [localfetcher#1] o.a.h.m.t.reduce.InMemoryMapOutput [InMemoryMapOutput.java : 94] Read 437 bytes from map-output for attempt_local1626972315_0001_m_000000_0
2021-12-26 01:30:49,718 INFO [localfetcher#1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 323] closeInMemoryFile -> map-output of size: 437, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->437
2021-12-26 01:30:49,719 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 76] EventFetcher is interrupted.. Returning
2021-12-26 01:30:49,720 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:30:49,720 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 695] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-12-26 01:30:49,727 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:30:49,727 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:30:49,730 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 762] Merged 1 segments, 437 bytes to disk to satisfy reduce memory limit
2021-12-26 01:30:49,731 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 792] Merging 1 files, 441 bytes from disk
2021-12-26 01:30:49,732 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 807] Merging 0 segments, 0 bytes from memory into reduce
2021-12-26 01:30:49,732 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:30:49,734 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:30:49,734 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:30:49,803 INFO [http-nio-8080-exec-4] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local1626972315_0001 running in uber mode : false
2021-12-26 01:30:49,804 INFO [http-nio-8080-exec-4] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 0%
2021-12-26 01:30:49,954 INFO [pool-8-thread-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-12-26 01:30:50,409 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local1626972315_0001_r_000000_0 is done. And is in the process of committing
2021-12-26 01:30:50,412 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:30:50,413 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1409] Task attempt_local1626972315_0001_r_000000_0 is allowed to commit now
2021-12-26 01:30:50,556 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 598] Saved output of task 'attempt_local1626972315_0001_r_000000_0' to hdfs://localhost:9000/output/product
2021-12-26 01:30:50,557 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-26 01:30:50,557 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local1626972315_0001_r_000000_0' done.
2021-12-26 01:30:50,557 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local1626972315_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1102
		FILE: Number of bytes written=494973
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=14
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=31
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=607125504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:30:50,558 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 353] Finishing task: attempt_local1626972315_0001_r_000000_0
2021-12-26 01:30:50,558 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] reduce task executor complete.
2021-12-26 01:30:50,813 INFO [http-nio-8080-exec-4] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 100%
2021-12-26 01:30:51,826 INFO [http-nio-8080-exec-4] org.apache.hadoop.mapreduce.Job [Job.java : 1658] Job job_local1626972315_0001 completed successfully
2021-12-26 01:30:51,833 INFO [http-nio-8080-exec-4] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 35
	File System Counters
		FILE: Number of bytes read=1290
		FILE: Number of bytes written=989505
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=580
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=62
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=285
		Total committed heap usage (bytes)=1214251008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:31:38,234 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 55] Starting HdfsApplication on DESKTOP-ORCB6UD with PID 32544 (C:\Users\UI\Desktop\bd-platform\springboot-hadoop\target\classes started by UI in C:\Users\UI\Desktop\bd-platform)
2021-12-26 01:31:38,237 INFO [main] com.bigdata.HdfsApplication [SpringApplication.java : 651] No active profile set, falling back to default profiles: default
2021-12-26 01:31:38,985 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 108] Tomcat initialized with port(s): 8080 (http)
2021-12-26 01:31:38,992 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Initializing ProtocolHandler ["http-nio-8080"]
2021-12-26 01:31:38,993 INFO [main] o.a.catalina.core.StandardService [DirectJDKLog.java : 173] Starting service [Tomcat]
2021-12-26 01:31:38,993 INFO [main] o.a.catalina.core.StandardEngine [DirectJDKLog.java : 173] Starting Servlet engine: [Apache Tomcat/9.0.39]
2021-12-26 01:31:39,086 INFO [main] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring embedded WebApplicationContext
2021-12-26 01:31:39,087 INFO [main] o.s.b.w.s.c.ServletWebServerApplicationContext [ServletWebServerApplicationContext.java : 285] Root WebApplicationContext: initialization completed in 815 ms
2021-12-26 01:31:39,230 INFO [main] o.s.s.c.ThreadPoolTaskExecutor [ExecutorConfigurationSupport.java : 181] Initializing ExecutorService 'applicationTaskExecutor'
2021-12-26 01:31:39,357 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Starting ProtocolHandler ["http-nio-8080"]
2021-12-26 01:31:39,377 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 220] Tomcat started on port(s): 8080 (http) with context path ''
2021-12-26 01:31:39,385 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 61] Started HdfsApplication in 1.497 seconds (JVM running for 2.819)
2021-12-26 01:31:55,132 INFO [http-nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-12-26 01:31:55,132 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 525] Initializing Servlet 'dispatcherServlet'
2021-12-26 01:31:55,136 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 547] Completed initialization in 4 ms
2021-12-26 01:31:55,251 WARN [http-nio-8080-exec-1] org.apache.hadoop.util.Shell [Shell.java : 694] Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:549)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:570)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:593)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:690)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3533)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3528)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:216)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:213)
	at com.bigdata.hadoop.HdfsService.getFileSystem(HdfsService.java:156)
	at com.bigdata.hadoop.HdfsService.existFile(HdfsService.java:191)
	at com.bigdata.hadoop.MapReduceService.wordCount(MapReduceService.java:30)
	at com.bigdata.controller.MapReduceAction.wordCount(MapReduceAction.java:38)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:652)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:469)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517)
	... 65 common frames omitted
2021-12-26 01:31:56,117 INFO [http-nio-8080-exec-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 01:31:56,424 INFO [http-nio-8080-exec-1] o.a.c.b.FluentPropertyBeanIntrospector [FluentPropertyBeanIntrospector.java : 147] Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-12-26 01:31:56,436 WARN [http-nio-8080-exec-1] o.a.h.metrics2.impl.MetricsConfig [MetricsConfig.java : 134] Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 01:31:56,448 INFO [http-nio-8080-exec-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 374] Scheduled Metric snapshot period at 10 second(s).
2021-12-26 01:31:56,449 INFO [http-nio-8080-exec-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 191] JobTracker metrics system started
2021-12-26 01:31:56,880 WARN [http-nio-8080-exec-1] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 01:31:56,893 WARN [http-nio-8080-exec-1] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 01:31:56,914 INFO [http-nio-8080-exec-1] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 01:31:56,943 INFO [http-nio-8080-exec-1] o.a.h.m.l.i.CombineFileInputFormat [CombineFileInputFormat.java : 428] DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 290
2021-12-26 01:31:56,965 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 01:31:57,030 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local361393679_0001
2021-12-26 01:31:57,031 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 01:31:57,118 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 01:31:57,119 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local361393679_0001
2021-12-26 01:31:57,122 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 01:31:57,128 INFO [Thread-19] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:31:57,128 INFO [Thread-19] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:31:57,130 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 01:31:57,372 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 01:31:57,373 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local361393679_0001_m_000000_0
2021-12-26 01:31:57,392 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:31:57,393 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:31:57,398 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:31:57,399 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:31:57,405 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: Paths:/user/hadoop/test/product.txt:0+290
2021-12-26 01:31:57,424 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 01:31:57,424 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 01:31:57,424 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 01:31:57,424 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 01:31:57,424 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 01:31:57,427 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 01:31:57,840 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 
2021-12-26 01:31:57,840 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 01:31:57,840 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1498] Spilling map output
2021-12-26 01:31:57,840 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1499] bufstart = 0; bufend = 412; bufvoid = 104857600
2021-12-26 01:31:57,840 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1501] kvstart = 26214396(104857584); kvend = 26214260(104857040); length = 137/6553600
2021-12-26 01:31:57,860 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1696] Finished spill 0
2021-12-26 01:31:57,876 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local361393679_0001_m_000000_0 is done. And is in the process of committing
2021-12-26 01:31:57,879 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map
2021-12-26 01:31:57,880 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local361393679_0001_m_000000_0' done.
2021-12-26 01:31:57,886 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local361393679_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=188
		FILE: Number of bytes written=492124
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Spilled Records=31
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=195
		Total committed heap usage (bytes)=647495680
	File Input Format Counters 
		Bytes Read=0
2021-12-26 01:31:57,886 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 277] Finishing task: attempt_local361393679_0001_m_000000_0
2021-12-26 01:31:57,888 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 01:31:57,889 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for reduce tasks
2021-12-26 01:31:57,890 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 330] Starting task: attempt_local361393679_0001_r_000000_0
2021-12-26 01:31:57,900 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:31:57,900 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:31:57,901 INFO [pool-8-thread-1] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:31:57,901 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:31:57,902 INFO [pool-8-thread-1] org.apache.hadoop.mapred.ReduceTask [ReduceTask.java : 363] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@65ca03d9
2021-12-26 01:31:57,904 WARN [pool-8-thread-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 01:31:57,914 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 208] MergerManager: memoryLimit=2651586560, maxSingleShuffleLimit=662896640, mergeThreshold=1750047232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-12-26 01:31:57,918 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 61] attempt_local361393679_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-12-26 01:31:57,947 INFO [localfetcher#1] o.a.h.m.task.reduce.LocalFetcher [LocalFetcher.java : 145] localfetcher#1 about to shuffle output of map attempt_local361393679_0001_m_000000_0 decomp: 437 len: 441 to MEMORY
2021-12-26 01:31:57,953 INFO [localfetcher#1] o.a.h.m.t.reduce.InMemoryMapOutput [InMemoryMapOutput.java : 94] Read 437 bytes from map-output for attempt_local361393679_0001_m_000000_0
2021-12-26 01:31:57,955 INFO [localfetcher#1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 323] closeInMemoryFile -> map-output of size: 437, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->437
2021-12-26 01:31:57,957 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 76] EventFetcher is interrupted.. Returning
2021-12-26 01:31:57,957 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:31:57,957 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 695] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-12-26 01:31:57,967 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:31:57,968 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:31:57,970 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 762] Merged 1 segments, 437 bytes to disk to satisfy reduce memory limit
2021-12-26 01:31:57,971 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 792] Merging 1 files, 441 bytes from disk
2021-12-26 01:31:57,972 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 807] Merging 0 segments, 0 bytes from memory into reduce
2021-12-26 01:31:57,972 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:31:57,974 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:31:57,975 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:31:58,126 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local361393679_0001 running in uber mode : false
2021-12-26 01:31:58,129 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 0%
2021-12-26 01:31:58,159 INFO [pool-8-thread-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-12-26 01:31:58,579 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local361393679_0001_r_000000_0 is done. And is in the process of committing
2021-12-26 01:31:58,581 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:31:58,581 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1409] Task attempt_local361393679_0001_r_000000_0 is allowed to commit now
2021-12-26 01:31:58,725 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 598] Saved output of task 'attempt_local361393679_0001_r_000000_0' to hdfs://localhost:9000/output/product
2021-12-26 01:31:58,726 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-26 01:31:58,726 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local361393679_0001_r_000000_0' done.
2021-12-26 01:31:58,726 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local361393679_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1102
		FILE: Number of bytes written=492565
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=14
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=31
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=647495680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:31:58,727 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 353] Finishing task: attempt_local361393679_0001_r_000000_0
2021-12-26 01:31:58,727 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] reduce task executor complete.
2021-12-26 01:31:59,140 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 100%
2021-12-26 01:31:59,140 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1658] Job job_local361393679_0001 completed successfully
2021-12-26 01:31:59,148 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 35
	File System Counters
		FILE: Number of bytes read=1290
		FILE: Number of bytes written=984689
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=580
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=62
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=195
		Total committed heap usage (bytes)=1294991360
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:32:23,169 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 55] Starting HdfsApplication on DESKTOP-ORCB6UD with PID 26296 (C:\Users\UI\Desktop\bd-platform\springboot-hadoop\target\classes started by UI in C:\Users\UI\Desktop\bd-platform)
2021-12-26 01:32:23,173 INFO [main] com.bigdata.HdfsApplication [SpringApplication.java : 651] No active profile set, falling back to default profiles: default
2021-12-26 01:32:23,860 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 108] Tomcat initialized with port(s): 8080 (http)
2021-12-26 01:32:23,867 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Initializing ProtocolHandler ["http-nio-8080"]
2021-12-26 01:32:23,868 INFO [main] o.a.catalina.core.StandardService [DirectJDKLog.java : 173] Starting service [Tomcat]
2021-12-26 01:32:23,868 INFO [main] o.a.catalina.core.StandardEngine [DirectJDKLog.java : 173] Starting Servlet engine: [Apache Tomcat/9.0.39]
2021-12-26 01:32:23,960 INFO [main] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring embedded WebApplicationContext
2021-12-26 01:32:23,960 INFO [main] o.s.b.w.s.c.ServletWebServerApplicationContext [ServletWebServerApplicationContext.java : 285] Root WebApplicationContext: initialization completed in 748 ms
2021-12-26 01:32:24,111 INFO [main] o.s.s.c.ThreadPoolTaskExecutor [ExecutorConfigurationSupport.java : 181] Initializing ExecutorService 'applicationTaskExecutor'
2021-12-26 01:32:24,243 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Starting ProtocolHandler ["http-nio-8080"]
2021-12-26 01:32:24,269 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 220] Tomcat started on port(s): 8080 (http) with context path ''
2021-12-26 01:32:24,278 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 61] Started HdfsApplication in 1.439 seconds (JVM running for 2.522)
2021-12-26 01:32:40,815 INFO [http-nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-12-26 01:32:40,816 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 525] Initializing Servlet 'dispatcherServlet'
2021-12-26 01:32:40,822 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 547] Completed initialization in 5 ms
2021-12-26 01:32:40,936 WARN [http-nio-8080-exec-1] org.apache.hadoop.util.Shell [Shell.java : 694] Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:549)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:570)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:593)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:690)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3533)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3528)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:216)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:213)
	at com.bigdata.hadoop.HdfsService.getFileSystem(HdfsService.java:156)
	at com.bigdata.hadoop.HdfsService.existFile(HdfsService.java:191)
	at com.bigdata.hadoop.MapReduceService.wordCount(MapReduceService.java:30)
	at com.bigdata.controller.MapReduceAction.wordCount(MapReduceAction.java:38)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:652)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:469)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517)
	... 65 common frames omitted
2021-12-26 01:32:41,824 INFO [http-nio-8080-exec-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 01:32:42,178 INFO [http-nio-8080-exec-1] o.a.c.b.FluentPropertyBeanIntrospector [FluentPropertyBeanIntrospector.java : 147] Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-12-26 01:32:42,192 WARN [http-nio-8080-exec-1] o.a.h.metrics2.impl.MetricsConfig [MetricsConfig.java : 134] Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 01:32:42,205 INFO [http-nio-8080-exec-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 374] Scheduled Metric snapshot period at 10 second(s).
2021-12-26 01:32:42,205 INFO [http-nio-8080-exec-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 191] JobTracker metrics system started
2021-12-26 01:32:42,670 WARN [http-nio-8080-exec-1] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 01:32:42,687 WARN [http-nio-8080-exec-1] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 01:32:42,722 INFO [http-nio-8080-exec-1] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 01:32:42,750 INFO [http-nio-8080-exec-1] o.a.h.m.l.i.CombineFileInputFormat [CombineFileInputFormat.java : 428] DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 290
2021-12-26 01:32:42,770 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 01:32:42,821 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local829926908_0001
2021-12-26 01:32:42,821 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 01:32:42,912 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 01:32:42,913 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local829926908_0001
2021-12-26 01:32:42,917 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 01:32:42,924 INFO [Thread-18] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:32:42,925 INFO [Thread-18] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:32:42,926 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 01:32:43,109 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 01:32:43,110 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local829926908_0001_m_000000_0
2021-12-26 01:32:43,129 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:32:43,130 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:32:43,136 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:32:43,137 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:32:43,143 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: Paths:/user/hadoop/test/product.txt:0+290
2021-12-26 01:32:43,193 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 01:32:43,194 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 01:32:43,194 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 01:32:43,194 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 01:32:43,194 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 01:32:43,198 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 01:32:43,410 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 
2021-12-26 01:32:43,410 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 01:32:43,410 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1498] Spilling map output
2021-12-26 01:32:43,410 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1499] bufstart = 0; bufend = 412; bufvoid = 104857600
2021-12-26 01:32:43,410 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1501] kvstart = 26214396(104857584); kvend = 26214260(104857040); length = 137/6553600
2021-12-26 01:32:43,425 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1696] Finished spill 0
2021-12-26 01:32:43,438 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local829926908_0001_m_000000_0 is done. And is in the process of committing
2021-12-26 01:32:43,440 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map
2021-12-26 01:32:43,440 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local829926908_0001_m_000000_0' done.
2021-12-26 01:32:43,444 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local829926908_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=188
		FILE: Number of bytes written=492124
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Spilled Records=31
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=312999936
	File Input Format Counters 
		Bytes Read=0
2021-12-26 01:32:43,444 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 277] Finishing task: attempt_local829926908_0001_m_000000_0
2021-12-26 01:32:43,445 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 01:32:43,446 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for reduce tasks
2021-12-26 01:32:43,446 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 330] Starting task: attempt_local829926908_0001_r_000000_0
2021-12-26 01:32:43,456 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:32:43,456 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:32:43,457 INFO [pool-8-thread-1] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:32:43,457 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:32:43,459 INFO [pool-8-thread-1] org.apache.hadoop.mapred.ReduceTask [ReduceTask.java : 363] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3f64cfb1
2021-12-26 01:32:43,460 WARN [pool-8-thread-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 01:32:43,468 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 208] MergerManager: memoryLimit=2651586560, maxSingleShuffleLimit=662896640, mergeThreshold=1750047232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-12-26 01:32:43,471 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 61] attempt_local829926908_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-12-26 01:32:43,669 INFO [localfetcher#1] o.a.h.m.task.reduce.LocalFetcher [LocalFetcher.java : 145] localfetcher#1 about to shuffle output of map attempt_local829926908_0001_m_000000_0 decomp: 437 len: 441 to MEMORY
2021-12-26 01:32:43,674 INFO [localfetcher#1] o.a.h.m.t.reduce.InMemoryMapOutput [InMemoryMapOutput.java : 94] Read 437 bytes from map-output for attempt_local829926908_0001_m_000000_0
2021-12-26 01:32:43,675 INFO [localfetcher#1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 323] closeInMemoryFile -> map-output of size: 437, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->437
2021-12-26 01:32:43,677 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 76] EventFetcher is interrupted.. Returning
2021-12-26 01:32:43,677 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:32:43,677 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 695] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-12-26 01:32:43,686 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:32:43,687 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:32:43,689 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 762] Merged 1 segments, 437 bytes to disk to satisfy reduce memory limit
2021-12-26 01:32:43,690 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 792] Merging 1 files, 441 bytes from disk
2021-12-26 01:32:43,690 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 807] Merging 0 segments, 0 bytes from memory into reduce
2021-12-26 01:32:43,690 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:32:43,692 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2021-12-26 01:32:43,693 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:32:43,933 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local829926908_0001 running in uber mode : false
2021-12-26 01:32:43,936 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 0%
2021-12-26 01:32:44,024 INFO [pool-8-thread-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-12-26 01:32:44,453 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local829926908_0001_r_000000_0 is done. And is in the process of committing
2021-12-26 01:32:44,457 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:32:44,458 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1409] Task attempt_local829926908_0001_r_000000_0 is allowed to commit now
2021-12-26 01:32:44,598 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 598] Saved output of task 'attempt_local829926908_0001_r_000000_0' to hdfs://localhost:9000/output/product
2021-12-26 01:32:44,599 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-26 01:32:44,600 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local829926908_0001_r_000000_0' done.
2021-12-26 01:32:44,600 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local829926908_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1102
		FILE: Number of bytes written=492565
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=290
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=14
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=31
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=167
		Total committed heap usage (bytes)=495452160
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:32:44,601 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 353] Finishing task: attempt_local829926908_0001_r_000000_0
2021-12-26 01:32:44,601 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] reduce task executor complete.
2021-12-26 01:32:44,939 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 100%
2021-12-26 01:32:45,951 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1658] Job job_local829926908_0001 completed successfully
2021-12-26 01:32:45,958 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 35
	File System Counters
		FILE: Number of bytes read=1290
		FILE: Number of bytes written=984689
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=580
		HDFS: Number of bytes written=311
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=10
		Map output records=35
		Map output bytes=412
		Map output materialized bytes=441
		Input split bytes=142
		Combine input records=35
		Combine output records=31
		Reduce input groups=31
		Reduce shuffle bytes=441
		Reduce input records=31
		Reduce output records=31
		Spilled Records=62
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=167
		Total committed heap usage (bytes)=808452096
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=311
2021-12-26 01:33:40,849 INFO [http-nio-8080-exec-3] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 01:33:41,093 WARN [http-nio-8080-exec-3] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 01:33:41,108 WARN [http-nio-8080-exec-3] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 01:33:41,109 WARN [http-nio-8080-exec-3] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 01:33:41,112 INFO [http-nio-8080-exec-3] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 01:33:41,120 INFO [http-nio-8080-exec-3] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 01:33:41,132 INFO [http-nio-8080-exec-3] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local746600376_0002
2021-12-26 01:33:41,133 INFO [http-nio-8080-exec-3] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 01:33:41,185 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 01:33:41,186 INFO [Thread-34] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 01:33:41,186 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local746600376_0002
2021-12-26 01:33:41,186 INFO [Thread-34] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:33:41,186 INFO [Thread-34] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:33:41,187 INFO [Thread-34] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 01:33:41,362 INFO [Thread-34] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 01:33:41,362 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local746600376_0002_m_000000_0
2021-12-26 01:33:41,363 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:33:41,363 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:33:41,363 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:33:41,363 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:33:41,377 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: hdfs://localhost:9000/user/hadoop/test/product.txt:0+290
2021-12-26 01:33:41,386 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 01:33:41,386 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 01:33:41,386 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 01:33:41,386 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 01:33:41,386 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 01:33:41,387 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 01:33:41,391 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 0, value = 10000001,灏忕背2锛�1,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@6f46e2bb
2021-12-26 01:33:41,392 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 01:33:41,406 INFO [Thread-34] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 01:33:41,630 WARN [Thread-34] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 590] job_local746600376_0002
java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 3
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 3
	at com.bigdata.hadoop.reduce.mapper.JoinMapper.map(JoinMapper.java:60)
	at com.bigdata.hadoop.reduce.mapper.JoinMapper.map(JoinMapper.java:18)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-12-26 01:33:42,186 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local746600376_0002 running in uber mode : false
2021-12-26 01:33:42,188 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 0% reduce 0%
2021-12-26 01:33:42,189 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1660] Job job_local746600376_0002 failed with state FAILED due to: NA
2021-12-26 01:33:42,190 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 0
2021-12-26 01:33:53,380 INFO [communication thread] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map > sort
2021-12-26 01:35:39,936 INFO [http-nio-8080-exec-7] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 01:35:40,251 WARN [http-nio-8080-exec-7] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 01:35:40,256 WARN [http-nio-8080-exec-7] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 01:35:40,258 WARN [http-nio-8080-exec-7] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 01:35:40,260 INFO [http-nio-8080-exec-7] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 01:35:40,266 INFO [http-nio-8080-exec-7] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 01:35:40,286 INFO [http-nio-8080-exec-7] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local1792486807_0003
2021-12-26 01:35:40,286 INFO [http-nio-8080-exec-7] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 01:35:40,344 INFO [http-nio-8080-exec-7] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 01:35:40,345 INFO [http-nio-8080-exec-7] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local1792486807_0003
2021-12-26 01:35:40,350 INFO [Thread-40] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 01:35:40,350 INFO [Thread-40] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:35:40,350 INFO [Thread-40] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:35:40,351 INFO [Thread-40] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 01:35:40,667 INFO [Thread-40] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 01:35:40,667 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local1792486807_0003_m_000000_0
2021-12-26 01:35:40,669 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:35:40,669 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:35:40,669 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:35:40,669 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:35:40,673 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: hdfs://localhost:9000/user/hadoop/test/product.txt:0+290
2021-12-26 01:35:40,677 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 01:35:40,677 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 01:35:40,677 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 01:35:40,677 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 01:35:40,677 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 01:35:40,678 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 01:35:40,682 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 0, value = 10000001,灏忕背2锛�1,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@7b758269
2021-12-26 01:35:40,682 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 01:35:40,689 INFO [Thread-40] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 01:35:40,835 WARN [Thread-40] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 590] job_local1792486807_0003
java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 3
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 3
	at com.bigdata.hadoop.reduce.mapper.JoinMapper.map(JoinMapper.java:60)
	at com.bigdata.hadoop.reduce.mapper.JoinMapper.map(JoinMapper.java:18)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-12-26 01:35:41,349 INFO [http-nio-8080-exec-7] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local1792486807_0003 running in uber mode : false
2021-12-26 01:35:41,350 INFO [http-nio-8080-exec-7] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 0% reduce 0%
2021-12-26 01:35:41,351 INFO [http-nio-8080-exec-7] org.apache.hadoop.mapreduce.Job [Job.java : 1660] Job job_local1792486807_0003 failed with state FAILED due to: NA
2021-12-26 01:35:41,352 INFO [http-nio-8080-exec-7] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 0
2021-12-26 01:35:48,394 INFO [http-nio-8080-exec-6] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 01:35:48,639 WARN [http-nio-8080-exec-6] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 01:35:48,643 WARN [http-nio-8080-exec-6] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 01:35:48,644 WARN [http-nio-8080-exec-6] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 01:35:48,647 INFO [http-nio-8080-exec-6] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 01:35:48,659 INFO [http-nio-8080-exec-6] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 01:35:48,674 INFO [http-nio-8080-exec-6] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local2007017337_0004
2021-12-26 01:35:48,674 INFO [http-nio-8080-exec-6] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 01:35:48,749 INFO [http-nio-8080-exec-6] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 01:35:48,749 INFO [http-nio-8080-exec-6] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local2007017337_0004
2021-12-26 01:35:48,750 INFO [Thread-45] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 01:35:48,750 INFO [Thread-45] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:35:48,751 INFO [Thread-45] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:35:48,751 INFO [Thread-45] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 01:35:48,923 INFO [Thread-45] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 01:35:48,924 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local2007017337_0004_m_000000_0
2021-12-26 01:35:48,928 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:35:48,928 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:35:48,929 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:35:48,930 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:35:48,949 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: hdfs://localhost:9000/user/hadoop/test/product.txt:0+290
2021-12-26 01:35:48,971 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 01:35:48,971 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 01:35:48,971 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 01:35:48,971 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 01:35:48,971 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 01:35:48,978 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 01:35:48,985 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 0, value = 10000001,灏忕背2锛�1,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@7d938fa7
2021-12-26 01:35:49,959 INFO [http-nio-8080-exec-6] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local2007017337_0004 running in uber mode : false
2021-12-26 01:35:50,024 INFO [http-nio-8080-exec-6] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 0% reduce 0%
2021-12-26 01:36:49,080 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 01:36:49,081 INFO [communication thread] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map > sort
2021-12-26 01:36:49,092 INFO [Thread-45] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 01:37:13,994 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 55] Starting HdfsApplication on DESKTOP-ORCB6UD with PID 1344 (C:\Users\UI\Desktop\bd-platform\springboot-hadoop\target\classes started by UI in C:\Users\UI\Desktop\bd-platform)
2021-12-26 01:37:14,004 INFO [main] com.bigdata.HdfsApplication [SpringApplication.java : 651] No active profile set, falling back to default profiles: default
2021-12-26 01:37:14,734 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 108] Tomcat initialized with port(s): 8080 (http)
2021-12-26 01:37:14,743 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Initializing ProtocolHandler ["http-nio-8080"]
2021-12-26 01:37:14,744 INFO [main] o.a.catalina.core.StandardService [DirectJDKLog.java : 173] Starting service [Tomcat]
2021-12-26 01:37:14,744 INFO [main] o.a.catalina.core.StandardEngine [DirectJDKLog.java : 173] Starting Servlet engine: [Apache Tomcat/9.0.39]
2021-12-26 01:37:14,832 INFO [main] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring embedded WebApplicationContext
2021-12-26 01:37:14,833 INFO [main] o.s.b.w.s.c.ServletWebServerApplicationContext [ServletWebServerApplicationContext.java : 285] Root WebApplicationContext: initialization completed in 766 ms
2021-12-26 01:37:14,970 INFO [main] o.s.s.c.ThreadPoolTaskExecutor [ExecutorConfigurationSupport.java : 181] Initializing ExecutorService 'applicationTaskExecutor'
2021-12-26 01:37:15,097 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Starting ProtocolHandler ["http-nio-8080"]
2021-12-26 01:37:15,116 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 220] Tomcat started on port(s): 8080 (http) with context path ''
2021-12-26 01:37:15,123 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 61] Started HdfsApplication in 1.42 seconds (JVM running for 2.756)
2021-12-26 01:37:20,520 INFO [http-nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-12-26 01:37:20,521 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 525] Initializing Servlet 'dispatcherServlet'
2021-12-26 01:37:20,525 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 547] Completed initialization in 4 ms
2021-12-26 01:37:20,639 WARN [http-nio-8080-exec-1] org.apache.hadoop.util.Shell [Shell.java : 694] Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:549)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:570)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:593)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:690)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3533)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3528)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:216)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:213)
	at com.bigdata.hadoop.HdfsService.getFileSystem(HdfsService.java:156)
	at com.bigdata.hadoop.HdfsService.existFile(HdfsService.java:191)
	at com.bigdata.hadoop.MapReduceService.join(MapReduceService.java:54)
	at com.bigdata.controller.MapReduceAction.join(MapReduceAction.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:652)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:469)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517)
	... 65 common frames omitted
2021-12-26 01:37:21,531 INFO [http-nio-8080-exec-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 01:37:21,913 INFO [http-nio-8080-exec-1] o.a.c.b.FluentPropertyBeanIntrospector [FluentPropertyBeanIntrospector.java : 147] Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-12-26 01:37:21,927 WARN [http-nio-8080-exec-1] o.a.h.metrics2.impl.MetricsConfig [MetricsConfig.java : 134] Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 01:37:21,940 INFO [http-nio-8080-exec-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 374] Scheduled Metric snapshot period at 10 second(s).
2021-12-26 01:37:21,941 INFO [http-nio-8080-exec-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 191] JobTracker metrics system started
2021-12-26 01:37:22,381 WARN [http-nio-8080-exec-1] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 01:37:22,394 WARN [http-nio-8080-exec-1] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 01:37:22,415 INFO [http-nio-8080-exec-1] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 01:37:22,463 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 01:37:22,526 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local1778841491_0001
2021-12-26 01:37:22,527 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 01:37:22,617 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 01:37:22,618 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local1778841491_0001
2021-12-26 01:37:22,621 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 01:37:22,630 INFO [Thread-19] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:37:22,630 INFO [Thread-19] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:37:22,632 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 01:37:22,860 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 01:37:22,861 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local1778841491_0001_m_000000_0
2021-12-26 01:37:22,879 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:37:22,880 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:37:22,885 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:37:22,885 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:37:22,896 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: hdfs://localhost:9000/user/hadoop/test/product.txt:0+290
2021-12-26 01:37:22,914 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 01:37:22,914 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 01:37:22,914 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 01:37:22,914 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 01:37:22,914 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 01:37:22,916 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 01:37:23,243 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 0, value = 10000001,小米2，1,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@11a443bd
2021-12-26 01:37:41,941 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local1778841491_0001 running in uber mode : false
2021-12-26 01:37:41,943 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 0% reduce 0%
2021-12-26 01:37:41,944 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 01:38:26,790 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 55] Starting HdfsApplication on DESKTOP-ORCB6UD with PID 16564 (C:\Users\UI\Desktop\bd-platform\springboot-hadoop\target\classes started by UI in C:\Users\UI\Desktop\bd-platform)
2021-12-26 01:38:26,794 INFO [main] com.bigdata.HdfsApplication [SpringApplication.java : 651] No active profile set, falling back to default profiles: default
2021-12-26 01:38:27,521 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 108] Tomcat initialized with port(s): 8080 (http)
2021-12-26 01:38:27,530 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Initializing ProtocolHandler ["http-nio-8080"]
2021-12-26 01:38:27,531 INFO [main] o.a.catalina.core.StandardService [DirectJDKLog.java : 173] Starting service [Tomcat]
2021-12-26 01:38:27,531 INFO [main] o.a.catalina.core.StandardEngine [DirectJDKLog.java : 173] Starting Servlet engine: [Apache Tomcat/9.0.39]
2021-12-26 01:38:27,763 INFO [main] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring embedded WebApplicationContext
2021-12-26 01:38:27,764 INFO [main] o.s.b.w.s.c.ServletWebServerApplicationContext [ServletWebServerApplicationContext.java : 285] Root WebApplicationContext: initialization completed in 922 ms
2021-12-26 01:38:28,003 INFO [main] o.s.s.c.ThreadPoolTaskExecutor [ExecutorConfigurationSupport.java : 181] Initializing ExecutorService 'applicationTaskExecutor'
2021-12-26 01:38:28,203 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Starting ProtocolHandler ["http-nio-8080"]
2021-12-26 01:38:28,231 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 220] Tomcat started on port(s): 8080 (http) with context path ''
2021-12-26 01:38:28,239 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 61] Started HdfsApplication in 1.838 seconds (JVM running for 3.124)
2021-12-26 01:39:02,499 INFO [http-nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-12-26 01:39:02,499 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 525] Initializing Servlet 'dispatcherServlet'
2021-12-26 01:39:02,504 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 547] Completed initialization in 4 ms
2021-12-26 01:39:02,676 WARN [http-nio-8080-exec-1] org.apache.hadoop.util.Shell [Shell.java : 694] Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:549)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:570)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:593)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:690)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3533)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3528)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:216)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:213)
	at com.bigdata.hadoop.HdfsService.getFileSystem(HdfsService.java:156)
	at com.bigdata.hadoop.HdfsService.uploadFile(HdfsService.java:366)
	at com.bigdata.controller.HdfsAction.uploadFile(HdfsAction.java:194)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:652)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:469)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517)
	... 64 common frames omitted
2021-12-26 01:39:18,341 INFO [http-nio-8080-exec-3] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 01:39:18,679 INFO [http-nio-8080-exec-3] o.a.c.b.FluentPropertyBeanIntrospector [FluentPropertyBeanIntrospector.java : 147] Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-12-26 01:39:18,693 WARN [http-nio-8080-exec-3] o.a.h.metrics2.impl.MetricsConfig [MetricsConfig.java : 134] Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 01:39:18,710 INFO [http-nio-8080-exec-3] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 374] Scheduled Metric snapshot period at 10 second(s).
2021-12-26 01:39:18,710 INFO [http-nio-8080-exec-3] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 191] JobTracker metrics system started
2021-12-26 01:39:19,187 WARN [http-nio-8080-exec-3] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 01:39:19,211 WARN [http-nio-8080-exec-3] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 01:39:19,232 INFO [http-nio-8080-exec-3] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 01:39:19,261 INFO [http-nio-8080-exec-3] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 01:39:19,316 INFO [http-nio-8080-exec-3] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local1247834112_0001
2021-12-26 01:39:19,316 INFO [http-nio-8080-exec-3] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 01:39:19,401 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 01:39:19,402 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local1247834112_0001
2021-12-26 01:39:19,403 INFO [Thread-23] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 01:39:19,411 INFO [Thread-23] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:39:19,411 INFO [Thread-23] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:39:19,412 INFO [Thread-23] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 01:39:19,605 INFO [Thread-23] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 01:39:19,607 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local1247834112_0001_m_000000_0
2021-12-26 01:39:19,632 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:39:19,632 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:39:19,638 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:39:19,640 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:39:19,660 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: hdfs://localhost:9000/user/hadoop/test/product.txt:0+270
2021-12-26 01:39:19,710 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 01:39:19,710 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 01:39:19,710 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 01:39:19,710 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 01:39:19,710 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 01:39:19,712 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 01:39:19,745 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 0, value = 10000001,小米2,1,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@3f9a4e58
2021-12-26 01:39:30,489 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 24, value = 10000002,苹果8,12,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@3f9a4e58
2021-12-26 01:39:30,488 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local1247834112_0001 running in uber mode : false
2021-12-26 01:39:30,489 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 49, value = 10000003,苹果8S,31,1400, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@3f9a4e58
2021-12-26 01:39:30,489 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 76, value = 10000004,华为P50,11,1300, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@3f9a4e58
2021-12-26 01:39:30,490 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 104, value = 10000005,华为P40,13,5100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@3f9a4e58
2021-12-26 01:39:30,490 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 132, value = 10000006,苹果11Pro,11,4100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@3f9a4e58
2021-12-26 01:39:30,490 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 162, value = 10000007,MacBook,13,3100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@3f9a4e58
2021-12-26 01:39:30,490 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 0% reduce 0%
2021-12-26 01:39:30,490 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 188, value = 10000008,肉松饼,11,1100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@3f9a4e58
2021-12-26 01:39:30,491 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 216, value = 10000009,方便面,13,1020, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@3f9a4e58
2021-12-26 01:39:30,491 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 244, value = 100000010,onePlus8,11,1100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@3f9a4e58
2021-12-26 01:39:30,493 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 
2021-12-26 01:39:30,494 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 01:39:30,495 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1498] Spilling map output
2021-12-26 01:39:30,495 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1499] bufstart = 0; bufend = 546; bufvoid = 104857600
2021-12-26 01:39:30,495 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1501] kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600
2021-12-26 01:39:30,503 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1696] Finished spill 0
2021-12-26 01:39:30,521 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local1247834112_0001_m_000000_0 is done. And is in the process of committing
2021-12-26 01:39:30,527 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map
2021-12-26 01:39:30,527 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local1247834112_0001_m_000000_0' done.
2021-12-26 01:39:30,531 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local1247834112_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=447
		FILE: Number of bytes written=494544
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=270
		HDFS: Number of bytes written=270
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=546
		Map output materialized bytes=572
		Input split bytes=115
		Combine input records=0
		Spilled Records=10
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=312475648
	File Input Format Counters 
		Bytes Read=270
2021-12-26 01:39:30,531 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 277] Finishing task: attempt_local1247834112_0001_m_000000_0
2021-12-26 01:39:30,532 INFO [Thread-23] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 01:39:30,534 INFO [Thread-23] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for reduce tasks
2021-12-26 01:39:30,534 INFO [pool-9-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 330] Starting task: attempt_local1247834112_0001_r_000000_0
2021-12-26 01:39:30,542 INFO [pool-9-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 01:39:30,542 INFO [pool-9-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 01:39:30,543 INFO [pool-9-thread-1] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 01:39:30,543 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 01:39:30,544 INFO [pool-9-thread-1] org.apache.hadoop.mapred.ReduceTask [ReduceTask.java : 363] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5dcc1a6
2021-12-26 01:39:30,545 WARN [pool-9-thread-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 01:39:30,552 INFO [pool-9-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 208] MergerManager: memoryLimit=2651586560, maxSingleShuffleLimit=662896640, mergeThreshold=1750047232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-12-26 01:39:30,554 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 61] attempt_local1247834112_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-12-26 01:39:30,580 INFO [localfetcher#1] o.a.h.m.task.reduce.LocalFetcher [LocalFetcher.java : 145] localfetcher#1 about to shuffle output of map attempt_local1247834112_0001_m_000000_0 decomp: 568 len: 572 to MEMORY
2021-12-26 01:39:30,589 INFO [localfetcher#1] o.a.h.m.t.reduce.InMemoryMapOutput [InMemoryMapOutput.java : 94] Read 568 bytes from map-output for attempt_local1247834112_0001_m_000000_0
2021-12-26 01:39:30,592 INFO [localfetcher#1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 323] closeInMemoryFile -> map-output of size: 568, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->568
2021-12-26 01:39:30,593 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 76] EventFetcher is interrupted.. Returning
2021-12-26 01:39:30,594 INFO [pool-9-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:39:30,594 INFO [pool-9-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 695] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-12-26 01:39:30,601 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:39:30,601 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 557 bytes
2021-12-26 01:39:30,604 INFO [pool-9-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 762] Merged 1 segments, 568 bytes to disk to satisfy reduce memory limit
2021-12-26 01:39:30,605 INFO [pool-9-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 792] Merging 1 files, 572 bytes from disk
2021-12-26 01:39:30,605 INFO [pool-9-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 807] Merging 0 segments, 0 bytes from memory into reduce
2021-12-26 01:39:30,605 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 01:39:30,608 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 557 bytes
2021-12-26 01:39:30,609 INFO [pool-9-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:39:30,779 INFO [pool-9-thread-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-12-26 01:39:30,782 INFO [pool-9-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000001, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6461d6c9, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@2331c0ed
2021-12-26 01:39:30,783 INFO [pool-9-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 100000010, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6461d6c9, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@2331c0ed
2021-12-26 01:39:30,783 INFO [pool-9-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000002, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6461d6c9, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@2331c0ed
2021-12-26 01:39:30,783 INFO [pool-9-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000003, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6461d6c9, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@2331c0ed
2021-12-26 01:39:30,783 INFO [pool-9-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000004, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6461d6c9, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@2331c0ed
2021-12-26 01:39:30,783 INFO [pool-9-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000005, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6461d6c9, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@2331c0ed
2021-12-26 01:39:30,783 INFO [pool-9-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000006, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6461d6c9, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@2331c0ed
2021-12-26 01:39:30,783 INFO [pool-9-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000007, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6461d6c9, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@2331c0ed
2021-12-26 01:39:30,784 INFO [pool-9-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000008, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6461d6c9, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@2331c0ed
2021-12-26 01:39:30,784 INFO [pool-9-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000009, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6461d6c9, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@2331c0ed
2021-12-26 01:39:30,913 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local1247834112_0001_r_000000_0 is done. And is in the process of committing
2021-12-26 01:39:30,915 INFO [pool-9-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 01:39:30,915 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1409] Task attempt_local1247834112_0001_r_000000_0 is allowed to commit now
2021-12-26 01:39:31,050 INFO [pool-9-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 598] Saved output of task 'attempt_local1247834112_0001_r_000000_0' to hdfs://localhost:9000/output/product
2021-12-26 01:39:31,051 INFO [pool-9-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-26 01:39:31,052 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local1247834112_0001_r_000000_0' done.
2021-12-26 01:39:31,052 INFO [pool-9-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local1247834112_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1623
		FILE: Number of bytes written=495116
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=270
		HDFS: Number of bytes written=270
		HDFS: Number of read operations=16
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=572
		Reduce input records=10
		Reduce output records=0
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=312475648
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2021-12-26 01:39:31,052 INFO [pool-9-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 353] Finishing task: attempt_local1247834112_0001_r_000000_0
2021-12-26 01:39:31,052 INFO [Thread-23] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] reduce task executor complete.
2021-12-26 01:39:31,494 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 100%
2021-12-26 01:39:32,496 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1658] Job job_local1247834112_0001 completed successfully
2021-12-26 01:39:32,503 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 35
	File System Counters
		FILE: Number of bytes read=2070
		FILE: Number of bytes written=989660
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=540
		HDFS: Number of bytes written=540
		HDFS: Number of read operations=27
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=546
		Map output materialized bytes=572
		Input split bytes=115
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=572
		Reduce input records=10
		Reduce output records=0
		Spilled Records=20
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=624951296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=270
	File Output Format Counters 
		Bytes Written=0
2021-12-26 12:50:31,530 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 55] Starting HdfsApplication on DESKTOP-ORCB6UD with PID 15588 (C:\Users\UI\Desktop\bd-platform\springboot-hadoop\target\classes started by UI in C:\Users\UI\Desktop\bd-platform)
2021-12-26 12:50:31,535 INFO [main] com.bigdata.HdfsApplication [SpringApplication.java : 651] No active profile set, falling back to default profiles: default
2021-12-26 12:50:33,060 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 108] Tomcat initialized with port(s): 8080 (http)
2021-12-26 12:50:33,071 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Initializing ProtocolHandler ["http-nio-8080"]
2021-12-26 12:50:33,072 INFO [main] o.a.catalina.core.StandardService [DirectJDKLog.java : 173] Starting service [Tomcat]
2021-12-26 12:50:33,072 INFO [main] o.a.catalina.core.StandardEngine [DirectJDKLog.java : 173] Starting Servlet engine: [Apache Tomcat/9.0.39]
2021-12-26 12:50:33,184 INFO [main] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring embedded WebApplicationContext
2021-12-26 12:50:33,184 INFO [main] o.s.b.w.s.c.ServletWebServerApplicationContext [ServletWebServerApplicationContext.java : 285] Root WebApplicationContext: initialization completed in 1600 ms
2021-12-26 12:50:33,426 INFO [main] o.s.s.c.ThreadPoolTaskExecutor [ExecutorConfigurationSupport.java : 181] Initializing ExecutorService 'applicationTaskExecutor'
2021-12-26 12:50:33,607 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Starting ProtocolHandler ["http-nio-8080"]
2021-12-26 12:50:33,627 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 220] Tomcat started on port(s): 8080 (http) with context path ''
2021-12-26 12:50:33,635 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 61] Started HdfsApplication in 2.626 seconds (JVM running for 4.061)
2021-12-26 12:51:01,456 INFO [http-nio-8080-exec-3] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-12-26 12:51:01,456 INFO [http-nio-8080-exec-3] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 525] Initializing Servlet 'dispatcherServlet'
2021-12-26 12:51:01,460 INFO [http-nio-8080-exec-3] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 547] Completed initialization in 4 ms
2021-12-26 12:51:01,820 WARN [http-nio-8080-exec-3] org.apache.hadoop.util.Shell [Shell.java : 694] Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:549)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:570)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:593)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:690)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3533)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3528)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:216)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:213)
	at com.bigdata.hadoop.HdfsService.getFileSystem(HdfsService.java:156)
	at com.bigdata.hadoop.HdfsService.existFile(HdfsService.java:191)
	at com.bigdata.hadoop.MapReduceService.join(MapReduceService.java:54)
	at com.bigdata.controller.MapReduceAction.join(MapReduceAction.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:652)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:469)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517)
	... 65 common frames omitted
2021-12-26 12:51:04,157 INFO [http-nio-8080-exec-3] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 12:51:04,516 INFO [http-nio-8080-exec-3] o.a.c.b.FluentPropertyBeanIntrospector [FluentPropertyBeanIntrospector.java : 147] Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-12-26 12:51:04,531 WARN [http-nio-8080-exec-3] o.a.h.metrics2.impl.MetricsConfig [MetricsConfig.java : 134] Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 12:51:04,542 INFO [http-nio-8080-exec-3] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 374] Scheduled Metric snapshot period at 10 second(s).
2021-12-26 12:51:04,543 INFO [http-nio-8080-exec-3] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 191] JobTracker metrics system started
2021-12-26 12:51:05,011 WARN [http-nio-8080-exec-3] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 12:51:05,034 WARN [http-nio-8080-exec-3] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 12:51:05,073 INFO [http-nio-8080-exec-3] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 12:51:05,321 INFO [http-nio-8080-exec-3] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 12:51:05,377 INFO [http-nio-8080-exec-3] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local715816394_0001
2021-12-26 12:51:05,377 INFO [http-nio-8080-exec-3] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 12:51:05,542 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 12:51:05,543 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local715816394_0001
2021-12-26 12:51:05,547 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 12:51:05,555 INFO [Thread-21] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 12:51:05,555 INFO [Thread-21] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 12:51:05,556 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 12:51:05,729 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 12:51:05,730 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local715816394_0001_m_000000_0
2021-12-26 12:51:05,756 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 12:51:05,756 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 12:51:05,763 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 12:51:05,764 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 12:51:05,778 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: hdfs://localhost:9000/user/hadoop/test/product.txt:0+270
2021-12-26 12:51:05,807 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 12:51:05,807 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 12:51:05,807 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 12:51:05,807 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 12:51:05,807 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 12:51:05,809 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 12:51:06,173 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 0, value = 10000001,小米2,1,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@6fa9f428
2021-12-26 12:51:06,174 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 24, value = 10000002,苹果8,12,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@6fa9f428
2021-12-26 12:51:06,174 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 49, value = 10000003,苹果8S,31,1400, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@6fa9f428
2021-12-26 12:51:06,174 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 76, value = 10000004,华为P50,11,1300, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@6fa9f428
2021-12-26 12:51:06,174 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 104, value = 10000005,华为P40,13,5100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@6fa9f428
2021-12-26 12:51:06,174 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 132, value = 10000006,苹果11Pro,11,4100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@6fa9f428
2021-12-26 12:51:06,174 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 162, value = 10000007,MacBook,13,3100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@6fa9f428
2021-12-26 12:51:06,174 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 188, value = 10000008,肉松饼,11,1100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@6fa9f428
2021-12-26 12:51:06,174 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 216, value = 10000009,方便面,13,1020, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@6fa9f428
2021-12-26 12:51:06,175 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 244, value = 100000010,onePlus8,11,1100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@6fa9f428
2021-12-26 12:51:06,176 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 
2021-12-26 12:51:06,196 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 12:51:06,197 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1498] Spilling map output
2021-12-26 12:51:06,197 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1499] bufstart = 0; bufend = 546; bufvoid = 104857600
2021-12-26 12:51:06,197 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1501] kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600
2021-12-26 12:51:06,233 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1696] Finished spill 0
2021-12-26 12:51:06,273 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local715816394_0001_m_000000_0 is done. And is in the process of committing
2021-12-26 12:51:06,277 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map
2021-12-26 12:51:06,277 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local715816394_0001_m_000000_0' done.
2021-12-26 12:51:06,284 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local715816394_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=177
		FILE: Number of bytes written=492136
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=270
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=546
		Map output materialized bytes=572
		Input split bytes=115
		Combine input records=0
		Spilled Records=10
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=251
		Total committed heap usage (bytes)=530579456
	File Input Format Counters 
		Bytes Read=270
2021-12-26 12:51:06,284 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 277] Finishing task: attempt_local715816394_0001_m_000000_0
2021-12-26 12:51:06,286 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 12:51:06,287 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for reduce tasks
2021-12-26 12:51:06,288 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 330] Starting task: attempt_local715816394_0001_r_000000_0
2021-12-26 12:51:06,299 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 12:51:06,299 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 12:51:06,299 INFO [pool-8-thread-1] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 12:51:06,299 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 12:51:06,301 INFO [pool-8-thread-1] org.apache.hadoop.mapred.ReduceTask [ReduceTask.java : 363] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1dd87c20
2021-12-26 12:51:06,302 WARN [pool-8-thread-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 12:51:06,310 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 208] MergerManager: memoryLimit=2651586560, maxSingleShuffleLimit=662896640, mergeThreshold=1750047232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-12-26 12:51:06,313 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 61] attempt_local715816394_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-12-26 12:51:06,337 INFO [localfetcher#1] o.a.h.m.task.reduce.LocalFetcher [LocalFetcher.java : 145] localfetcher#1 about to shuffle output of map attempt_local715816394_0001_m_000000_0 decomp: 568 len: 572 to MEMORY
2021-12-26 12:51:06,346 INFO [localfetcher#1] o.a.h.m.t.reduce.InMemoryMapOutput [InMemoryMapOutput.java : 94] Read 568 bytes from map-output for attempt_local715816394_0001_m_000000_0
2021-12-26 12:51:06,349 INFO [localfetcher#1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 323] closeInMemoryFile -> map-output of size: 568, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->568
2021-12-26 12:51:06,350 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 76] EventFetcher is interrupted.. Returning
2021-12-26 12:51:06,350 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 12:51:06,351 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 695] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-12-26 12:51:06,360 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 12:51:06,360 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 557 bytes
2021-12-26 12:51:06,363 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 762] Merged 1 segments, 568 bytes to disk to satisfy reduce memory limit
2021-12-26 12:51:06,363 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 792] Merging 1 files, 572 bytes from disk
2021-12-26 12:51:06,364 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 807] Merging 0 segments, 0 bytes from memory into reduce
2021-12-26 12:51:06,364 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 12:51:06,367 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 557 bytes
2021-12-26 12:51:06,367 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 12:51:06,552 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local715816394_0001 running in uber mode : false
2021-12-26 12:51:06,555 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 0%
2021-12-26 12:51:06,650 INFO [pool-8-thread-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-12-26 12:51:06,655 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000001, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@7efe54b4, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@67f1004f
2021-12-26 12:51:06,655 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 100000010, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@7efe54b4, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@67f1004f
2021-12-26 12:51:06,655 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000002, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@7efe54b4, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@67f1004f
2021-12-26 12:51:06,655 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000003, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@7efe54b4, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@67f1004f
2021-12-26 12:51:06,655 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000004, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@7efe54b4, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@67f1004f
2021-12-26 12:51:06,655 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000005, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@7efe54b4, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@67f1004f
2021-12-26 12:51:06,656 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000006, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@7efe54b4, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@67f1004f
2021-12-26 12:51:06,656 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000007, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@7efe54b4, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@67f1004f
2021-12-26 12:51:06,656 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000008, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@7efe54b4, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@67f1004f
2021-12-26 12:51:06,656 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000009, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@7efe54b4, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@67f1004f
2021-12-26 12:51:06,812 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local715816394_0001_r_000000_0 is done. And is in the process of committing
2021-12-26 12:51:06,814 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 12:51:06,814 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1409] Task attempt_local715816394_0001_r_000000_0 is allowed to commit now
2021-12-26 12:51:07,045 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 598] Saved output of task 'attempt_local715816394_0001_r_000000_0' to hdfs://localhost:9000/output/product
2021-12-26 12:51:07,046 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-26 12:51:07,047 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local715816394_0001_r_000000_0' done.
2021-12-26 12:51:07,048 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local715816394_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1353
		FILE: Number of bytes written=492708
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=270
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=14
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=572
		Reduce input records=10
		Reduce output records=0
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=530579456
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2021-12-26 12:51:07,048 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 353] Finishing task: attempt_local715816394_0001_r_000000_0
2021-12-26 12:51:07,048 INFO [Thread-21] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] reduce task executor complete.
2021-12-26 12:51:07,558 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 100%
2021-12-26 12:51:07,559 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1658] Job job_local715816394_0001 completed successfully
2021-12-26 12:51:07,579 INFO [http-nio-8080-exec-3] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 35
	File System Counters
		FILE: Number of bytes read=1530
		FILE: Number of bytes written=984844
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=540
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=546
		Map output materialized bytes=572
		Input split bytes=115
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=572
		Reduce input records=10
		Reduce output records=0
		Spilled Records=20
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=251
		Total committed heap usage (bytes)=1061158912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=270
	File Output Format Counters 
		Bytes Written=0
2021-12-26 13:23:30,657 INFO [http-nio-8080-exec-2] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 13:23:30,888 WARN [http-nio-8080-exec-2] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 13:23:30,897 WARN [http-nio-8080-exec-2] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 13:23:30,898 WARN [http-nio-8080-exec-2] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 13:23:30,901 INFO [http-nio-8080-exec-2] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 13:23:30,908 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 13:23:30,925 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local124436069_0002
2021-12-26 13:23:30,925 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 13:23:30,984 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 13:23:30,985 INFO [Thread-36] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 13:23:30,985 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local124436069_0002
2021-12-26 13:23:30,985 INFO [Thread-36] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 13:23:30,986 INFO [Thread-36] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 13:23:30,986 INFO [Thread-36] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 13:23:31,126 INFO [Thread-36] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 13:23:31,126 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local124436069_0002_m_000000_0
2021-12-26 13:23:31,128 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 13:23:31,128 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 13:23:31,128 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 13:23:31,128 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 13:23:31,132 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: hdfs://localhost:9000/user/hadoop/test/product.txt:0+270
2021-12-26 13:23:31,173 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 13:23:31,173 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 13:23:31,173 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 13:23:31,173 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 13:23:31,173 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 13:23:31,174 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 13:23:31,179 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 0, value = 10000001,小米2,1,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@27d03df7
2021-12-26 13:23:31,179 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 24, value = 10000002,苹果8,12,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@27d03df7
2021-12-26 13:23:31,179 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 49, value = 10000003,苹果8S,31,1400, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@27d03df7
2021-12-26 13:23:31,179 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 76, value = 10000004,华为P50,11,1300, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@27d03df7
2021-12-26 13:23:31,179 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 104, value = 10000005,华为P40,13,5100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@27d03df7
2021-12-26 13:23:31,180 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 132, value = 10000006,苹果11Pro,11,4100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@27d03df7
2021-12-26 13:23:31,180 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 162, value = 10000007,MacBook,13,3100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@27d03df7
2021-12-26 13:23:31,180 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 188, value = 10000008,肉松饼,11,1100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@27d03df7
2021-12-26 13:23:31,180 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 216, value = 10000009,方便面,13,1020, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@27d03df7
2021-12-26 13:23:31,180 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 244, value = 100000010,onePlus8,11,1100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@27d03df7
2021-12-26 13:23:31,180 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 
2021-12-26 13:23:31,180 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 13:23:31,180 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1498] Spilling map output
2021-12-26 13:23:31,180 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1499] bufstart = 0; bufend = 546; bufvoid = 104857600
2021-12-26 13:23:31,181 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1501] kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600
2021-12-26 13:23:31,185 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1696] Finished spill 0
2021-12-26 13:23:31,188 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local124436069_0002_m_000000_0 is done. And is in the process of committing
2021-12-26 13:23:31,190 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map
2021-12-26 13:23:31,191 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local124436069_0002_m_000000_0' done.
2021-12-26 13:23:31,191 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local124436069_0002_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=1530
		FILE: Number of bytes written=984315
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=540
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=546
		Map output materialized bytes=572
		Input split bytes=115
		Combine input records=0
		Spilled Records=10
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=530579456
	File Input Format Counters 
		Bytes Read=270
2021-12-26 13:23:31,191 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 277] Finishing task: attempt_local124436069_0002_m_000000_0
2021-12-26 13:23:31,191 INFO [Thread-36] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 13:23:31,192 INFO [Thread-36] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for reduce tasks
2021-12-26 13:23:31,192 INFO [pool-13-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 330] Starting task: attempt_local124436069_0002_r_000000_0
2021-12-26 13:23:31,193 INFO [pool-13-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 13:23:31,194 INFO [pool-13-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 13:23:31,194 INFO [pool-13-thread-1] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 13:23:31,194 INFO [pool-13-thread-1] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 13:23:31,194 INFO [pool-13-thread-1] org.apache.hadoop.mapred.ReduceTask [ReduceTask.java : 363] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6f0b5aa
2021-12-26 13:23:31,194 WARN [pool-13-thread-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 13:23:31,195 INFO [pool-13-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 208] MergerManager: memoryLimit=2651586560, maxSingleShuffleLimit=662896640, mergeThreshold=1750047232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-12-26 13:23:31,195 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 61] attempt_local124436069_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-12-26 13:23:31,197 INFO [localfetcher#2] o.a.h.m.task.reduce.LocalFetcher [LocalFetcher.java : 145] localfetcher#2 about to shuffle output of map attempt_local124436069_0002_m_000000_0 decomp: 568 len: 572 to MEMORY
2021-12-26 13:23:31,199 INFO [localfetcher#2] o.a.h.m.t.reduce.InMemoryMapOutput [InMemoryMapOutput.java : 94] Read 568 bytes from map-output for attempt_local124436069_0002_m_000000_0
2021-12-26 13:23:31,199 INFO [localfetcher#2] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 323] closeInMemoryFile -> map-output of size: 568, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->568
2021-12-26 13:23:31,200 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 76] EventFetcher is interrupted.. Returning
2021-12-26 13:23:31,200 INFO [pool-13-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 13:23:31,200 INFO [pool-13-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 695] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-12-26 13:23:31,204 INFO [pool-13-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 13:23:31,204 INFO [pool-13-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 557 bytes
2021-12-26 13:23:31,205 INFO [pool-13-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 762] Merged 1 segments, 568 bytes to disk to satisfy reduce memory limit
2021-12-26 13:23:31,206 INFO [pool-13-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 792] Merging 1 files, 572 bytes from disk
2021-12-26 13:23:31,206 INFO [pool-13-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 807] Merging 0 segments, 0 bytes from memory into reduce
2021-12-26 13:23:31,206 INFO [pool-13-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 13:23:31,209 INFO [pool-13-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 557 bytes
2021-12-26 13:23:31,209 INFO [pool-13-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 13:23:31,362 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000001, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@78097d64, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@32bd92b1
2021-12-26 13:23:43,275 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local124436069_0002 running in uber mode : false
2021-12-26 13:23:47,748 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 0%
2021-12-26 13:24:13,794 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 100000010, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@78097d64, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@32bd92b1
2021-12-26 13:24:13,795 INFO [communication thread] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-26 13:25:38,684 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000002, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@78097d64, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@32bd92b1
2021-12-26 13:25:38,684 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 73%
2021-12-26 13:25:38,686 INFO [communication thread] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-26 13:25:38,686 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000003, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@78097d64, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@32bd92b1
2021-12-26 13:25:38,686 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000004, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@78097d64, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@32bd92b1
2021-12-26 13:25:38,687 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000005, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@78097d64, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@32bd92b1
2021-12-26 13:25:38,687 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000006, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@78097d64, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@32bd92b1
2021-12-26 13:25:38,688 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000007, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@78097d64, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@32bd92b1
2021-12-26 13:25:38,688 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000008, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@78097d64, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@32bd92b1
2021-12-26 13:25:38,689 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000009, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@78097d64, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@32bd92b1
2021-12-26 13:25:43,500 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 55] Starting HdfsApplication on DESKTOP-ORCB6UD with PID 26780 (C:\Users\UI\Desktop\bd-platform\springboot-hadoop\target\classes started by UI in C:\Users\UI\Desktop\bd-platform)
2021-12-26 13:25:43,505 INFO [main] com.bigdata.HdfsApplication [SpringApplication.java : 651] No active profile set, falling back to default profiles: default
2021-12-26 13:25:44,170 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 108] Tomcat initialized with port(s): 8080 (http)
2021-12-26 13:25:44,178 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Initializing ProtocolHandler ["http-nio-8080"]
2021-12-26 13:25:44,178 INFO [main] o.a.catalina.core.StandardService [DirectJDKLog.java : 173] Starting service [Tomcat]
2021-12-26 13:25:44,179 INFO [main] o.a.catalina.core.StandardEngine [DirectJDKLog.java : 173] Starting Servlet engine: [Apache Tomcat/9.0.39]
2021-12-26 13:25:44,270 INFO [main] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring embedded WebApplicationContext
2021-12-26 13:25:44,270 INFO [main] o.s.b.w.s.c.ServletWebServerApplicationContext [ServletWebServerApplicationContext.java : 285] Root WebApplicationContext: initialization completed in 726 ms
2021-12-26 13:25:44,407 INFO [main] o.s.s.c.ThreadPoolTaskExecutor [ExecutorConfigurationSupport.java : 181] Initializing ExecutorService 'applicationTaskExecutor'
2021-12-26 13:25:44,532 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Starting ProtocolHandler ["http-nio-8080"]
2021-12-26 13:25:44,555 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 220] Tomcat started on port(s): 8080 (http) with context path ''
2021-12-26 13:25:44,564 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 61] Started HdfsApplication in 1.362 seconds (JVM running for 2.432)
2021-12-26 13:35:31,489 INFO [http-nio-8080-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-12-26 13:35:31,489 INFO [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 525] Initializing Servlet 'dispatcherServlet'
2021-12-26 13:35:31,494 INFO [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 547] Completed initialization in 5 ms
2021-12-26 13:35:31,603 WARN [http-nio-8080-exec-2] org.apache.hadoop.util.Shell [Shell.java : 694] Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:549)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:570)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:593)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:690)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3533)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3528)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:216)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:213)
	at com.bigdata.hadoop.HdfsService.getFileSystem(HdfsService.java:156)
	at com.bigdata.hadoop.HdfsService.existFile(HdfsService.java:191)
	at com.bigdata.hadoop.MapReduceService.join(MapReduceService.java:54)
	at com.bigdata.controller.MapReduceAction.join(MapReduceAction.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:652)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:469)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517)
	... 65 common frames omitted
2021-12-26 13:35:32,549 INFO [http-nio-8080-exec-2] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 13:35:32,925 INFO [http-nio-8080-exec-2] o.a.c.b.FluentPropertyBeanIntrospector [FluentPropertyBeanIntrospector.java : 147] Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-12-26 13:35:32,937 WARN [http-nio-8080-exec-2] o.a.h.metrics2.impl.MetricsConfig [MetricsConfig.java : 134] Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 13:35:32,952 INFO [http-nio-8080-exec-2] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 374] Scheduled Metric snapshot period at 10 second(s).
2021-12-26 13:35:32,952 INFO [http-nio-8080-exec-2] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 191] JobTracker metrics system started
2021-12-26 13:35:33,419 WARN [http-nio-8080-exec-2] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 13:35:33,434 WARN [http-nio-8080-exec-2] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 13:35:33,455 INFO [http-nio-8080-exec-2] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 13:35:33,524 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 13:35:33,573 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local1057667613_0001
2021-12-26 13:35:33,574 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 13:35:33,660 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 13:35:33,661 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local1057667613_0001
2021-12-26 13:35:33,664 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 13:35:33,670 INFO [Thread-18] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 13:35:33,670 INFO [Thread-18] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 13:35:33,671 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 13:35:33,894 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 13:35:33,895 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local1057667613_0001_m_000000_0
2021-12-26 13:35:33,914 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 13:35:33,915 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 13:35:33,919 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 13:35:33,920 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 13:35:33,927 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: hdfs://localhost:9000/user/hadoop/test/product.txt:0+270
2021-12-26 13:35:33,944 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 13:35:33,944 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 13:35:33,945 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 13:35:33,945 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 13:35:33,945 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 13:35:33,946 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 13:35:34,209 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 0, value = 10000001,小米2,1,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@1794d4ce
2021-12-26 13:35:34,210 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 24, value = 10000002,苹果8,12,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@1794d4ce
2021-12-26 13:35:34,210 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 49, value = 10000003,苹果8S,31,1400, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@1794d4ce
2021-12-26 13:35:34,210 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 76, value = 10000004,华为P50,11,1300, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@1794d4ce
2021-12-26 13:35:34,210 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 104, value = 10000005,华为P40,13,5100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@1794d4ce
2021-12-26 13:35:34,210 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 132, value = 10000006,苹果11Pro,11,4100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@1794d4ce
2021-12-26 13:35:34,210 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 162, value = 10000007,MacBook,13,3100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@1794d4ce
2021-12-26 13:35:34,210 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 188, value = 10000008,肉松饼,11,1100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@1794d4ce
2021-12-26 13:35:34,210 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 216, value = 10000009,方便面,13,1020, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@1794d4ce
2021-12-26 13:35:34,210 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 244, value = 100000010,onePlus8,11,1100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@1794d4ce
2021-12-26 13:35:34,212 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 
2021-12-26 13:35:34,213 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 13:35:34,214 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1498] Spilling map output
2021-12-26 13:35:34,214 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1499] bufstart = 0; bufend = 546; bufvoid = 104857600
2021-12-26 13:35:34,214 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1501] kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600
2021-12-26 13:35:34,222 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1696] Finished spill 0
2021-12-26 13:35:34,234 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local1057667613_0001_m_000000_0 is done. And is in the process of committing
2021-12-26 13:35:34,236 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map
2021-12-26 13:35:34,237 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local1057667613_0001_m_000000_0' done.
2021-12-26 13:35:34,241 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local1057667613_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=177
		FILE: Number of bytes written=494544
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=270
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=546
		Map output materialized bytes=572
		Input split bytes=115
		Combine input records=0
		Spilled Records=10
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=196
		Total committed heap usage (bytes)=643301376
	File Input Format Counters 
		Bytes Read=270
2021-12-26 13:35:34,241 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 277] Finishing task: attempt_local1057667613_0001_m_000000_0
2021-12-26 13:35:34,242 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 13:35:34,243 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for reduce tasks
2021-12-26 13:35:34,244 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 330] Starting task: attempt_local1057667613_0001_r_000000_0
2021-12-26 13:35:34,252 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 13:35:34,252 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 13:35:34,252 INFO [pool-8-thread-1] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 13:35:34,253 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 13:35:34,254 INFO [pool-8-thread-1] org.apache.hadoop.mapred.ReduceTask [ReduceTask.java : 363] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@414bd290
2021-12-26 13:35:34,255 WARN [pool-8-thread-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 13:35:34,263 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 208] MergerManager: memoryLimit=2651586560, maxSingleShuffleLimit=662896640, mergeThreshold=1750047232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-12-26 13:35:34,266 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 61] attempt_local1057667613_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-12-26 13:35:34,290 INFO [localfetcher#1] o.a.h.m.task.reduce.LocalFetcher [LocalFetcher.java : 145] localfetcher#1 about to shuffle output of map attempt_local1057667613_0001_m_000000_0 decomp: 568 len: 572 to MEMORY
2021-12-26 13:35:34,295 INFO [localfetcher#1] o.a.h.m.t.reduce.InMemoryMapOutput [InMemoryMapOutput.java : 94] Read 568 bytes from map-output for attempt_local1057667613_0001_m_000000_0
2021-12-26 13:35:34,296 INFO [localfetcher#1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 323] closeInMemoryFile -> map-output of size: 568, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->568
2021-12-26 13:35:34,297 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 76] EventFetcher is interrupted.. Returning
2021-12-26 13:35:34,298 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 13:35:34,298 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 695] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-12-26 13:35:34,305 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 13:35:34,306 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 557 bytes
2021-12-26 13:35:34,307 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 762] Merged 1 segments, 568 bytes to disk to satisfy reduce memory limit
2021-12-26 13:35:34,308 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 792] Merging 1 files, 572 bytes from disk
2021-12-26 13:35:34,309 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 807] Merging 0 segments, 0 bytes from memory into reduce
2021-12-26 13:35:34,309 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 13:35:34,312 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 557 bytes
2021-12-26 13:35:34,312 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 13:35:34,514 INFO [pool-8-thread-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-12-26 13:35:34,519 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000001, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6d2d7994, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@1bd854fa
2021-12-26 13:35:34,558 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 100000010, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6d2d7994, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@1bd854fa
2021-12-26 13:35:34,558 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000002, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6d2d7994, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@1bd854fa
2021-12-26 13:35:34,559 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000003, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6d2d7994, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@1bd854fa
2021-12-26 13:35:34,559 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000004, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6d2d7994, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@1bd854fa
2021-12-26 13:35:34,559 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000005, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6d2d7994, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@1bd854fa
2021-12-26 13:35:34,559 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000006, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6d2d7994, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@1bd854fa
2021-12-26 13:35:34,560 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000007, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6d2d7994, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@1bd854fa
2021-12-26 13:35:34,560 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000008, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6d2d7994, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@1bd854fa
2021-12-26 13:35:34,560 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000009, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@6d2d7994, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@1bd854fa
2021-12-26 13:35:34,669 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local1057667613_0001 running in uber mode : false
2021-12-26 13:35:34,670 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 0%
2021-12-26 13:35:35,107 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local1057667613_0001_r_000000_0 is done. And is in the process of committing
2021-12-26 13:35:35,114 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 13:35:35,115 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1409] Task attempt_local1057667613_0001_r_000000_0 is allowed to commit now
2021-12-26 13:35:35,329 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 598] Saved output of task 'attempt_local1057667613_0001_r_000000_0' to hdfs://localhost:9000/output/product
2021-12-26 13:35:35,330 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-26 13:35:35,330 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local1057667613_0001_r_000000_0' done.
2021-12-26 13:35:35,331 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local1057667613_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1353
		FILE: Number of bytes written=495116
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=270
		HDFS: Number of bytes written=1102
		HDFS: Number of read operations=14
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=572
		Reduce input records=10
		Reduce output records=10
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=643301376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=1102
2021-12-26 13:35:35,331 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 353] Finishing task: attempt_local1057667613_0001_r_000000_0
2021-12-26 13:35:35,332 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] reduce task executor complete.
2021-12-26 13:35:35,681 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 100%
2021-12-26 13:35:36,690 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1658] Job job_local1057667613_0001 completed successfully
2021-12-26 13:35:36,699 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 35
	File System Counters
		FILE: Number of bytes read=1530
		FILE: Number of bytes written=989660
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=540
		HDFS: Number of bytes written=1102
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=546
		Map output materialized bytes=572
		Input split bytes=115
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=572
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=196
		Total committed heap usage (bytes)=1286602752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=270
	File Output Format Counters 
		Bytes Written=1102
2021-12-26 18:07:17,455 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 55] Starting HdfsApplication on DESKTOP-ORCB6UD with PID 20804 (C:\Users\UI\Desktop\bd-platform\springboot-hadoop\target\classes started by UI in C:\Users\UI\Desktop\bd-platform)
2021-12-26 18:07:17,460 INFO [main] com.bigdata.HdfsApplication [SpringApplication.java : 651] No active profile set, falling back to default profiles: default
2021-12-26 18:07:18,317 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 108] Tomcat initialized with port(s): 8080 (http)
2021-12-26 18:07:18,326 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Initializing ProtocolHandler ["http-nio-8080"]
2021-12-26 18:07:18,327 INFO [main] o.a.catalina.core.StandardService [DirectJDKLog.java : 173] Starting service [Tomcat]
2021-12-26 18:07:18,328 INFO [main] o.a.catalina.core.StandardEngine [DirectJDKLog.java : 173] Starting Servlet engine: [Apache Tomcat/9.0.39]
2021-12-26 18:07:18,475 INFO [main] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring embedded WebApplicationContext
2021-12-26 18:07:18,475 INFO [main] o.s.b.w.s.c.ServletWebServerApplicationContext [ServletWebServerApplicationContext.java : 285] Root WebApplicationContext: initialization completed in 976 ms
2021-12-26 18:07:18,645 INFO [main] o.s.s.c.ThreadPoolTaskExecutor [ExecutorConfigurationSupport.java : 181] Initializing ExecutorService 'applicationTaskExecutor'
2021-12-26 18:07:18,791 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Starting ProtocolHandler ["http-nio-8080"]
2021-12-26 18:07:18,818 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 220] Tomcat started on port(s): 8080 (http) with context path ''
2021-12-26 18:07:18,827 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 61] Started HdfsApplication in 1.722 seconds (JVM running for 2.866)
2021-12-26 18:07:31,922 INFO [http-nio-8080-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-12-26 18:07:31,923 INFO [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 525] Initializing Servlet 'dispatcherServlet'
2021-12-26 18:07:31,927 INFO [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 547] Completed initialization in 4 ms
2021-12-26 18:07:32,119 WARN [http-nio-8080-exec-2] org.apache.hadoop.util.Shell [Shell.java : 694] Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:549)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:570)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:593)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:690)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3533)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3528)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:216)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:213)
	at com.bigdata.hadoop.HdfsService.getFileSystem(HdfsService.java:156)
	at com.bigdata.hadoop.HdfsService.existFile(HdfsService.java:191)
	at com.bigdata.hadoop.MapReduceService.join(MapReduceService.java:54)
	at com.bigdata.controller.MapReduceAction.join(MapReduceAction.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:652)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:469)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517)
	... 65 common frames omitted
2021-12-26 18:07:33,339 INFO [http-nio-8080-exec-2] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 18:07:33,623 INFO [http-nio-8080-exec-2] o.a.c.b.FluentPropertyBeanIntrospector [FluentPropertyBeanIntrospector.java : 147] Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-12-26 18:07:33,635 WARN [http-nio-8080-exec-2] o.a.h.metrics2.impl.MetricsConfig [MetricsConfig.java : 134] Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 18:07:33,646 INFO [http-nio-8080-exec-2] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 374] Scheduled Metric snapshot period at 10 second(s).
2021-12-26 18:07:33,646 INFO [http-nio-8080-exec-2] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 191] JobTracker metrics system started
2021-12-26 18:07:34,136 WARN [http-nio-8080-exec-2] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 18:07:34,151 WARN [http-nio-8080-exec-2] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 18:07:34,171 INFO [http-nio-8080-exec-2] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 18:07:34,414 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 18:07:34,468 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local1683429849_0001
2021-12-26 18:07:34,468 INFO [http-nio-8080-exec-2] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 18:07:34,564 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 18:07:34,566 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local1683429849_0001
2021-12-26 18:07:34,568 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 18:07:34,574 INFO [Thread-19] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 18:07:34,574 INFO [Thread-19] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 18:07:34,575 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 18:07:34,799 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 18:07:34,800 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local1683429849_0001_m_000000_0
2021-12-26 18:07:34,820 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 18:07:34,821 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 18:07:34,827 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 18:07:34,829 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 18:07:34,840 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: hdfs://localhost:9000/user/hadoop/test/product.txt:0+270
2021-12-26 18:07:34,862 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 18:07:34,862 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 18:07:34,862 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 18:07:34,862 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 18:07:34,862 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 18:07:34,864 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 18:07:35,170 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 0, value = 10000001,小米2,1,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@9565616
2021-12-26 18:07:35,171 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 24, value = 10000002,苹果8,12,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@9565616
2021-12-26 18:07:35,171 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 49, value = 10000003,苹果8S,31,1400, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@9565616
2021-12-26 18:07:35,171 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 76, value = 10000004,华为P50,11,1300, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@9565616
2021-12-26 18:07:35,171 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 104, value = 10000005,华为P40,13,5100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@9565616
2021-12-26 18:07:35,171 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 132, value = 10000006,苹果11Pro,11,4100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@9565616
2021-12-26 18:07:35,171 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 162, value = 10000007,MacBook,13,3100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@9565616
2021-12-26 18:07:35,172 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 188, value = 10000008,肉松饼,11,1100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@9565616
2021-12-26 18:07:35,172 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 216, value = 10000009,方便面,13,1020, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@9565616
2021-12-26 18:07:35,172 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 244, value = 100000010,onePlus8,11,1100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@9565616
2021-12-26 18:07:35,174 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 
2021-12-26 18:07:35,177 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 18:07:35,177 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1498] Spilling map output
2021-12-26 18:07:35,177 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1499] bufstart = 0; bufend = 546; bufvoid = 104857600
2021-12-26 18:07:35,178 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1501] kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600
2021-12-26 18:07:35,187 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1696] Finished spill 0
2021-12-26 18:07:35,200 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local1683429849_0001_m_000000_0 is done. And is in the process of committing
2021-12-26 18:07:35,203 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map
2021-12-26 18:07:35,203 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local1683429849_0001_m_000000_0' done.
2021-12-26 18:07:35,207 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local1683429849_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=177
		FILE: Number of bytes written=494544
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=270
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=546
		Map output materialized bytes=572
		Input split bytes=115
		Combine input records=0
		Spilled Records=10
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=211
		Total committed heap usage (bytes)=642252800
	File Input Format Counters 
		Bytes Read=270
2021-12-26 18:07:35,207 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 277] Finishing task: attempt_local1683429849_0001_m_000000_0
2021-12-26 18:07:35,208 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 18:07:35,210 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for reduce tasks
2021-12-26 18:07:35,211 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 330] Starting task: attempt_local1683429849_0001_r_000000_0
2021-12-26 18:07:35,219 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 18:07:35,220 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 18:07:35,220 INFO [pool-8-thread-1] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 18:07:35,220 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 18:07:35,221 INFO [pool-8-thread-1] org.apache.hadoop.mapred.ReduceTask [ReduceTask.java : 363] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@211b6ba3
2021-12-26 18:07:35,223 WARN [pool-8-thread-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 18:07:35,231 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 208] MergerManager: memoryLimit=2651586560, maxSingleShuffleLimit=662896640, mergeThreshold=1750047232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-12-26 18:07:35,234 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 61] attempt_local1683429849_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-12-26 18:07:35,260 INFO [localfetcher#1] o.a.h.m.task.reduce.LocalFetcher [LocalFetcher.java : 145] localfetcher#1 about to shuffle output of map attempt_local1683429849_0001_m_000000_0 decomp: 568 len: 572 to MEMORY
2021-12-26 18:07:35,269 INFO [localfetcher#1] o.a.h.m.t.reduce.InMemoryMapOutput [InMemoryMapOutput.java : 94] Read 568 bytes from map-output for attempt_local1683429849_0001_m_000000_0
2021-12-26 18:07:35,271 INFO [localfetcher#1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 323] closeInMemoryFile -> map-output of size: 568, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->568
2021-12-26 18:07:35,273 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 76] EventFetcher is interrupted.. Returning
2021-12-26 18:07:35,273 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 18:07:35,273 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 695] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-12-26 18:07:35,282 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 18:07:35,282 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 557 bytes
2021-12-26 18:07:35,285 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 762] Merged 1 segments, 568 bytes to disk to satisfy reduce memory limit
2021-12-26 18:07:35,285 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 792] Merging 1 files, 572 bytes from disk
2021-12-26 18:07:35,286 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 807] Merging 0 segments, 0 bytes from memory into reduce
2021-12-26 18:07:35,286 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 18:07:35,288 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 557 bytes
2021-12-26 18:07:35,289 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 18:07:35,573 INFO [pool-8-thread-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-12-26 18:07:35,580 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000001, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@1698cf4b, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@4ec26623
2021-12-26 18:07:35,581 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000001, amount=0, pname=小米2, categoryId=1, price=100.0, flag=1), data = (null)
2021-12-26 18:07:35,581 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 100000010, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@1698cf4b, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@4ec26623
2021-12-26 18:07:35,581 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=100000010, amount=0, pname=onePlus8, categoryId=11, price=1100.0, flag=1), data = (null)
2021-12-26 18:07:35,581 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000002, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@1698cf4b, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@4ec26623
2021-12-26 18:07:35,582 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000002, amount=0, pname=苹果8, categoryId=12, price=100.0, flag=1), data = (null)
2021-12-26 18:07:35,582 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000003, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@1698cf4b, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@4ec26623
2021-12-26 18:07:35,582 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000003, amount=0, pname=苹果8S, categoryId=31, price=1400.0, flag=1), data = (null)
2021-12-26 18:07:35,582 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000004, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@1698cf4b, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@4ec26623
2021-12-26 18:07:35,582 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000004, amount=0, pname=华为P50, categoryId=11, price=1300.0, flag=1), data = (null)
2021-12-26 18:07:35,582 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000005, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@1698cf4b, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@4ec26623
2021-12-26 18:07:35,582 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000005, amount=0, pname=华为P40, categoryId=13, price=5100.0, flag=1), data = (null)
2021-12-26 18:07:35,582 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000006, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@1698cf4b, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@4ec26623
2021-12-26 18:07:35,582 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000006, amount=0, pname=苹果11Pro, categoryId=11, price=4100.0, flag=1), data = (null)
2021-12-26 18:07:35,583 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000007, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@1698cf4b, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@4ec26623
2021-12-26 18:07:35,583 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000007, amount=0, pname=MacBook, categoryId=13, price=3100.0, flag=1), data = (null)
2021-12-26 18:07:35,583 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local1683429849_0001 running in uber mode : false
2021-12-26 18:07:35,583 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000008, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@1698cf4b, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@4ec26623
2021-12-26 18:07:35,583 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000008, amount=0, pname=肉松饼, categoryId=11, price=1100.0, flag=1), data = (null)
2021-12-26 18:07:35,584 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000009, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@1698cf4b, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@4ec26623
2021-12-26 18:07:35,584 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 0%
2021-12-26 18:07:35,585 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000009, amount=0, pname=方便面, categoryId=13, price=1020.0, flag=1), data = (null)
2021-12-26 18:07:36,017 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local1683429849_0001_r_000000_0 is done. And is in the process of committing
2021-12-26 18:07:36,018 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 18:07:36,018 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1409] Task attempt_local1683429849_0001_r_000000_0 is allowed to commit now
2021-12-26 18:07:36,152 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 598] Saved output of task 'attempt_local1683429849_0001_r_000000_0' to hdfs://localhost:9000/output/product
2021-12-26 18:07:36,154 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-26 18:07:36,154 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local1683429849_0001_r_000000_0' done.
2021-12-26 18:07:36,155 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local1683429849_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1353
		FILE: Number of bytes written=495116
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=270
		HDFS: Number of bytes written=1102
		HDFS: Number of read operations=14
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=572
		Reduce input records=10
		Reduce output records=10
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=642252800
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=1102
2021-12-26 18:07:36,155 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 353] Finishing task: attempt_local1683429849_0001_r_000000_0
2021-12-26 18:07:36,155 INFO [Thread-19] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] reduce task executor complete.
2021-12-26 18:07:36,597 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 100%
2021-12-26 18:07:36,599 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1658] Job job_local1683429849_0001 completed successfully
2021-12-26 18:07:36,622 INFO [http-nio-8080-exec-2] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 35
	File System Counters
		FILE: Number of bytes read=1530
		FILE: Number of bytes written=989660
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=540
		HDFS: Number of bytes written=1102
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=546
		Map output materialized bytes=572
		Input split bytes=115
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=572
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=211
		Total committed heap usage (bytes)=1284505600
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=270
	File Output Format Counters 
		Bytes Written=1102
2021-12-26 18:18:19,616 INFO [http-nio-8080-exec-5] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 18:18:19,873 WARN [http-nio-8080-exec-5] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 18:18:19,882 WARN [http-nio-8080-exec-5] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 18:18:19,883 WARN [http-nio-8080-exec-5] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 18:18:19,886 INFO [http-nio-8080-exec-5] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 18:18:19,894 INFO [http-nio-8080-exec-5] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 18:18:19,907 INFO [http-nio-8080-exec-5] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local673055586_0002
2021-12-26 18:18:19,907 INFO [http-nio-8080-exec-5] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 18:18:19,967 INFO [http-nio-8080-exec-5] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 18:18:19,967 INFO [http-nio-8080-exec-5] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local673055586_0002
2021-12-26 18:18:19,968 INFO [Thread-35] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 18:18:19,968 INFO [Thread-35] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 18:18:19,968 INFO [Thread-35] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 18:18:19,968 INFO [Thread-35] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 18:18:20,142 INFO [Thread-35] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 18:18:20,143 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local673055586_0002_m_000000_0
2021-12-26 18:18:20,144 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 18:18:20,144 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 18:18:20,144 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 18:18:20,144 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 18:18:20,148 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: hdfs://localhost:9000/user/hadoop/test/product.txt:0+270
2021-12-26 18:18:20,171 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 18:18:20,173 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 18:18:20,173 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 18:18:20,173 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 18:18:20,173 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 18:18:20,174 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 18:18:20,187 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 0, value = 10000001,小米2,1,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@26bd5412
2021-12-26 18:18:20,187 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 24, value = 10000002,苹果8,12,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@26bd5412
2021-12-26 18:18:20,187 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 49, value = 10000003,苹果8S,31,1400, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@26bd5412
2021-12-26 18:18:20,187 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 76, value = 10000004,华为P50,11,1300, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@26bd5412
2021-12-26 18:18:20,188 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 104, value = 10000005,华为P40,13,5100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@26bd5412
2021-12-26 18:18:20,188 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 132, value = 10000006,苹果11Pro,11,4100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@26bd5412
2021-12-26 18:18:20,188 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 162, value = 10000007,MacBook,13,3100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@26bd5412
2021-12-26 18:18:20,188 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 188, value = 10000008,肉松饼,11,1100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@26bd5412
2021-12-26 18:18:20,188 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 216, value = 10000009,方便面,13,1020, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@26bd5412
2021-12-26 18:18:20,189 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 244, value = 100000010,onePlus8,11,1100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@26bd5412
2021-12-26 18:18:20,189 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 
2021-12-26 18:18:20,189 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 18:18:20,189 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1498] Spilling map output
2021-12-26 18:18:20,189 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1499] bufstart = 0; bufend = 546; bufvoid = 104857600
2021-12-26 18:18:20,189 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1501] kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600
2021-12-26 18:18:20,194 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1696] Finished spill 0
2021-12-26 18:18:20,198 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local673055586_0002_m_000000_0 is done. And is in the process of committing
2021-12-26 18:18:20,200 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map
2021-12-26 18:18:20,200 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local673055586_0002_m_000000_0' done.
2021-12-26 18:18:20,200 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local673055586_0002_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=1530
		FILE: Number of bytes written=986723
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=540
		HDFS: Number of bytes written=1102
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=546
		Map output materialized bytes=572
		Input split bytes=115
		Combine input records=0
		Spilled Records=10
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=642252800
	File Input Format Counters 
		Bytes Read=270
2021-12-26 18:18:20,200 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 277] Finishing task: attempt_local673055586_0002_m_000000_0
2021-12-26 18:18:20,200 INFO [Thread-35] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 18:18:20,201 INFO [Thread-35] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for reduce tasks
2021-12-26 18:18:20,201 INFO [pool-13-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 330] Starting task: attempt_local673055586_0002_r_000000_0
2021-12-26 18:18:20,203 INFO [pool-13-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 18:18:20,203 INFO [pool-13-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 18:18:20,203 INFO [pool-13-thread-1] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 18:18:20,203 INFO [pool-13-thread-1] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 18:18:20,203 INFO [pool-13-thread-1] org.apache.hadoop.mapred.ReduceTask [ReduceTask.java : 363] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1f16b696
2021-12-26 18:18:20,203 WARN [pool-13-thread-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 18:18:20,205 INFO [pool-13-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 208] MergerManager: memoryLimit=2651586560, maxSingleShuffleLimit=662896640, mergeThreshold=1750047232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-12-26 18:18:20,205 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 61] attempt_local673055586_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-12-26 18:18:20,208 INFO [localfetcher#2] o.a.h.m.task.reduce.LocalFetcher [LocalFetcher.java : 145] localfetcher#2 about to shuffle output of map attempt_local673055586_0002_m_000000_0 decomp: 568 len: 572 to MEMORY
2021-12-26 18:18:20,210 INFO [localfetcher#2] o.a.h.m.t.reduce.InMemoryMapOutput [InMemoryMapOutput.java : 94] Read 568 bytes from map-output for attempt_local673055586_0002_m_000000_0
2021-12-26 18:18:20,211 INFO [localfetcher#2] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 323] closeInMemoryFile -> map-output of size: 568, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->568
2021-12-26 18:18:20,211 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 76] EventFetcher is interrupted.. Returning
2021-12-26 18:18:20,212 INFO [pool-13-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 18:18:20,212 INFO [pool-13-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 695] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-12-26 18:18:20,215 INFO [pool-13-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 18:18:20,215 INFO [pool-13-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 557 bytes
2021-12-26 18:18:20,216 INFO [pool-13-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 762] Merged 1 segments, 568 bytes to disk to satisfy reduce memory limit
2021-12-26 18:18:20,217 INFO [pool-13-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 792] Merging 1 files, 572 bytes from disk
2021-12-26 18:18:20,217 INFO [pool-13-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 807] Merging 0 segments, 0 bytes from memory into reduce
2021-12-26 18:18:20,217 INFO [pool-13-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 18:18:20,219 INFO [pool-13-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 557 bytes
2021-12-26 18:18:20,219 INFO [pool-13-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 18:18:20,434 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000001, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@61761281, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@294f2a4
2021-12-26 18:18:22,290 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000001, amount=0, pname=小米2, categoryId=1, price=100.0, flag=1), data = (null)
2021-12-26 18:18:22,290 INFO [http-nio-8080-exec-5] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local673055586_0002 running in uber mode : false
2021-12-26 18:18:22,290 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 100000010, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@61761281, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@294f2a4
2021-12-26 18:18:22,291 INFO [http-nio-8080-exec-5] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 0%
2021-12-26 18:18:24,647 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=100000010, amount=0, pname=onePlus8, categoryId=11, price=1100.0, flag=1), data = (null)
2021-12-26 18:18:24,648 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000002, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@61761281, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@294f2a4
2021-12-26 18:18:25,365 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000002, amount=0, pname=苹果8, categoryId=12, price=100.0, flag=1), data = (null)
2021-12-26 18:18:25,365 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000003, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@61761281, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@294f2a4
2021-12-26 18:18:28,302 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000003, amount=0, pname=苹果8S, categoryId=31, price=1400.0, flag=1), data = (null)
2021-12-26 18:18:28,302 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000004, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@61761281, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@294f2a4
2021-12-26 18:18:28,303 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000004, amount=0, pname=华为P50, categoryId=11, price=1300.0, flag=1), data = (null)
2021-12-26 18:18:28,303 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000005, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@61761281, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@294f2a4
2021-12-26 18:18:28,303 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000005, amount=0, pname=华为P40, categoryId=13, price=5100.0, flag=1), data = (null)
2021-12-26 18:18:28,303 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000006, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@61761281, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@294f2a4
2021-12-26 18:18:28,303 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000006, amount=0, pname=苹果11Pro, categoryId=11, price=4100.0, flag=1), data = (null)
2021-12-26 18:18:28,303 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000007, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@61761281, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@294f2a4
2021-12-26 18:18:28,303 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000007, amount=0, pname=MacBook, categoryId=13, price=3100.0, flag=1), data = (null)
2021-12-26 18:18:28,303 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000008, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@61761281, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@294f2a4
2021-12-26 18:18:28,303 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000008, amount=0, pname=肉松饼, categoryId=11, price=1100.0, flag=1), data = (null)
2021-12-26 18:18:28,304 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 28] reduce text key = 10000009, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@61761281, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@294f2a4
2021-12-26 18:18:28,304 INFO [pool-13-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 62] context.write = OrderInfo(orderId=0, orderDate=, pid=10000009, amount=0, pname=方便面, categoryId=13, price=1020.0, flag=1), data = (null)
2021-12-26 18:18:28,924 INFO [pool-13-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local673055586_0002_r_000000_0 is done. And is in the process of committing
2021-12-26 18:18:28,926 INFO [pool-13-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 18:18:28,926 INFO [pool-13-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1409] Task attempt_local673055586_0002_r_000000_0 is allowed to commit now
2021-12-26 18:18:29,059 INFO [pool-13-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 598] Saved output of task 'attempt_local673055586_0002_r_000000_0' to hdfs://localhost:9000/output/product
2021-12-26 18:18:29,060 INFO [pool-13-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-26 18:18:29,060 INFO [pool-13-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local673055586_0002_r_000000_0' done.
2021-12-26 18:18:29,060 INFO [pool-13-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local673055586_0002_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=2706
		FILE: Number of bytes written=987295
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=540
		HDFS: Number of bytes written=2204
		HDFS: Number of read operations=28
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=572
		Reduce input records=10
		Reduce output records=10
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=642252800
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=1102
2021-12-26 18:18:29,060 INFO [pool-13-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 353] Finishing task: attempt_local673055586_0002_r_000000_0
2021-12-26 18:18:29,060 INFO [Thread-35] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] reduce task executor complete.
2021-12-26 18:18:29,315 INFO [http-nio-8080-exec-5] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 100%
2021-12-26 18:18:30,327 INFO [http-nio-8080-exec-5] org.apache.hadoop.mapreduce.Job [Job.java : 1658] Job job_local673055586_0002 completed successfully
2021-12-26 18:18:30,332 INFO [http-nio-8080-exec-5] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 35
	File System Counters
		FILE: Number of bytes read=4236
		FILE: Number of bytes written=1974018
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1080
		HDFS: Number of bytes written=3306
		HDFS: Number of read operations=51
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=18
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=546
		Map output materialized bytes=572
		Input split bytes=115
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=572
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1284505600
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=270
	File Output Format Counters 
		Bytes Written=1102
2021-12-26 18:24:56,120 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 55] Starting HdfsApplication on DESKTOP-ORCB6UD with PID 1716 (C:\Users\UI\Desktop\bd-platform\springboot-hadoop\target\classes started by UI in C:\Users\UI\Desktop\bd-platform)
2021-12-26 18:24:56,123 INFO [main] com.bigdata.HdfsApplication [SpringApplication.java : 651] No active profile set, falling back to default profiles: default
2021-12-26 18:24:56,798 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 108] Tomcat initialized with port(s): 8080 (http)
2021-12-26 18:24:56,805 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Initializing ProtocolHandler ["http-nio-8080"]
2021-12-26 18:24:56,806 INFO [main] o.a.catalina.core.StandardService [DirectJDKLog.java : 173] Starting service [Tomcat]
2021-12-26 18:24:56,806 INFO [main] o.a.catalina.core.StandardEngine [DirectJDKLog.java : 173] Starting Servlet engine: [Apache Tomcat/9.0.39]
2021-12-26 18:24:56,892 INFO [main] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring embedded WebApplicationContext
2021-12-26 18:24:56,892 INFO [main] o.s.b.w.s.c.ServletWebServerApplicationContext [ServletWebServerApplicationContext.java : 285] Root WebApplicationContext: initialization completed in 728 ms
2021-12-26 18:24:57,025 INFO [main] o.s.s.c.ThreadPoolTaskExecutor [ExecutorConfigurationSupport.java : 181] Initializing ExecutorService 'applicationTaskExecutor'
2021-12-26 18:24:57,148 INFO [main] o.a.coyote.http11.Http11NioProtocol [DirectJDKLog.java : 173] Starting ProtocolHandler ["http-nio-8080"]
2021-12-26 18:24:57,166 INFO [main] o.s.b.w.e.tomcat.TomcatWebServer [TomcatWebServer.java : 220] Tomcat started on port(s): 8080 (http) with context path ''
2021-12-26 18:24:57,173 INFO [main] com.bigdata.HdfsApplication [StartupInfoLogger.java : 61] Started HdfsApplication in 1.355 seconds (JVM running for 2.446)
2021-12-26 18:25:05,777 INFO [http-nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] [DirectJDKLog.java : 173] Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-12-26 18:25:05,777 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 525] Initializing Servlet 'dispatcherServlet'
2021-12-26 18:25:05,781 INFO [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet [FrameworkServlet.java : 547] Completed initialization in 4 ms
2021-12-26 18:25:05,894 WARN [http-nio-8080-exec-1] org.apache.hadoop.util.Shell [Shell.java : 694] Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:549)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:570)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:593)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:690)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3533)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3528)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:216)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:213)
	at com.bigdata.hadoop.HdfsService.getFileSystem(HdfsService.java:156)
	at com.bigdata.hadoop.HdfsService.existFile(HdfsService.java:191)
	at com.bigdata.hadoop.MapReduceService.join(MapReduceService.java:54)
	at com.bigdata.controller.MapReduceAction.join(MapReduceAction.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:652)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:469)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517)
	... 65 common frames omitted
2021-12-26 18:25:06,744 INFO [http-nio-8080-exec-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2021-12-26 18:25:07,019 INFO [http-nio-8080-exec-1] o.a.c.b.FluentPropertyBeanIntrospector [FluentPropertyBeanIntrospector.java : 147] Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-12-26 18:25:07,030 WARN [http-nio-8080-exec-1] o.a.h.metrics2.impl.MetricsConfig [MetricsConfig.java : 134] Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 18:25:07,041 INFO [http-nio-8080-exec-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 374] Scheduled Metric snapshot period at 10 second(s).
2021-12-26 18:25:07,041 INFO [http-nio-8080-exec-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 191] JobTracker metrics system started
2021-12-26 18:25:07,479 WARN [http-nio-8080-exec-1] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 147] Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-12-26 18:25:07,492 WARN [http-nio-8080-exec-1] o.a.h.mapreduce.JobResourceUploader [JobResourceUploader.java : 480] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-12-26 18:25:07,512 INFO [http-nio-8080-exec-1] o.a.h.m.lib.input.FileInputFormat [FileInputFormat.java : 292] Total input files to process : 1
2021-12-26 18:25:07,576 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 205] number of splits:1
2021-12-26 18:25:07,623 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 301] Submitting tokens for job: job_local1686705408_0001
2021-12-26 18:25:07,623 INFO [http-nio-8080-exec-1] o.a.hadoop.mapreduce.JobSubmitter [JobSubmitter.java : 302] Executing with tokens: []
2021-12-26 18:25:07,710 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1574] The url to track the job: http://localhost:8080/
2021-12-26 18:25:07,711 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1619] Running job: job_local1686705408_0001
2021-12-26 18:25:07,713 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 501] OutputCommitter set in config null
2021-12-26 18:25:07,719 INFO [Thread-18] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 18:25:07,719 INFO [Thread-18] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 18:25:07,721 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 519] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-12-26 18:25:07,902 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for map tasks
2021-12-26 18:25:07,903 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 252] Starting task: attempt_local1686705408_0001_m_000000_0
2021-12-26 18:25:07,922 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 18:25:07,922 INFO [LocalJobRunner Map Task Executor #0] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 18:25:07,926 INFO [LocalJobRunner Map Task Executor #0] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 18:25:07,927 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 18:25:07,933 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 768] Processing split: hdfs://localhost:9000/user/hadoop/test/product.txt:0+270
2021-12-26 18:25:07,952 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1219] (EQUATOR) 0 kvi 26214396(104857584)
2021-12-26 18:25:07,952 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1012] mapreduce.task.io.sort.mb: 100
2021-12-26 18:25:07,952 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1013] soft limit at 83886080
2021-12-26 18:25:07,952 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1014] bufstart = 0; bufvoid = 104857600
2021-12-26 18:25:07,952 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1015] kvstart = 26214396; length = 6553600
2021-12-26 18:25:07,954 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 409] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-12-26 18:25:08,211 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 0, value = 10000001,小米2,1,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@2dc3966
2021-12-26 18:25:08,211 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 24, value = 10000002,苹果8,12,100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@2dc3966
2021-12-26 18:25:08,212 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 49, value = 10000003,苹果8S,31,1400, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@2dc3966
2021-12-26 18:25:08,212 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 76, value = 10000004,华为P50,11,1300, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@2dc3966
2021-12-26 18:25:08,212 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 104, value = 10000005,华为P40,13,5100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@2dc3966
2021-12-26 18:25:08,212 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 132, value = 10000006,苹果11Pro,11,4100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@2dc3966
2021-12-26 18:25:08,212 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 162, value = 10000007,MacBook,13,3100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@2dc3966
2021-12-26 18:25:08,212 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 188, value = 10000008,肉松饼,11,1100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@2dc3966
2021-12-26 18:25:08,212 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 216, value = 10000009,方便面,13,1020, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@2dc3966
2021-12-26 18:25:08,212 INFO [LocalJobRunner Map Task Executor #0] c.b.hadoop.reduce.mapper.JoinMapper [JoinMapper.java : 32] map data key = 244, value = 100000010,onePlus8,11,1100, context = org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context@2dc3966
2021-12-26 18:25:08,214 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 
2021-12-26 18:25:08,216 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1476] Starting flush of map output
2021-12-26 18:25:08,216 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1498] Spilling map output
2021-12-26 18:25:08,216 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1499] bufstart = 0; bufend = 546; bufvoid = 104857600
2021-12-26 18:25:08,216 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1501] kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600
2021-12-26 18:25:08,225 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask [MapTask.java : 1696] Finished spill 0
2021-12-26 18:25:08,237 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local1686705408_0001_m_000000_0 is done. And is in the process of committing
2021-12-26 18:25:08,239 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] map
2021-12-26 18:25:08,239 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local1686705408_0001_m_000000_0' done.
2021-12-26 18:25:08,242 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local1686705408_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=177
		FILE: Number of bytes written=494544
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=270
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=546
		Map output materialized bytes=572
		Input split bytes=115
		Combine input records=0
		Spilled Records=10
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=189
		Total committed heap usage (bytes)=642777088
	File Input Format Counters 
		Bytes Read=270
2021-12-26 18:25:08,242 INFO [LocalJobRunner Map Task Executor #0] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 277] Finishing task: attempt_local1686705408_0001_m_000000_0
2021-12-26 18:25:08,243 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] map task executor complete.
2021-12-26 18:25:08,244 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 478] Waiting for reduce tasks
2021-12-26 18:25:08,246 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 330] Starting task: attempt_local1686705408_0001_r_000000_0
2021-12-26 18:25:08,254 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 140] File Output Committer Algorithm version is 2
2021-12-26 18:25:08,254 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 155] FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-12-26 18:25:08,254 INFO [pool-8-thread-1] o.a.h.y.util.ProcfsBasedProcessTree [ProcfsBasedProcessTree.java : 178] ProcfsBasedProcessTree currently is supported only on Linux.
2021-12-26 18:25:08,254 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 625]  Using ResourceCalculatorProcessTree : null
2021-12-26 18:25:08,255 INFO [pool-8-thread-1] org.apache.hadoop.mapred.ReduceTask [ReduceTask.java : 363] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3263abbc
2021-12-26 18:25:08,256 WARN [pool-8-thread-1] o.a.h.m.impl.MetricsSystemImpl [MetricsSystemImpl.java : 151] JobTracker metrics system already initialized!
2021-12-26 18:25:08,263 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 208] MergerManager: memoryLimit=2651586560, maxSingleShuffleLimit=662896640, mergeThreshold=1750047232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-12-26 18:25:08,266 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 61] attempt_local1686705408_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-12-26 18:25:08,288 INFO [localfetcher#1] o.a.h.m.task.reduce.LocalFetcher [LocalFetcher.java : 145] localfetcher#1 about to shuffle output of map attempt_local1686705408_0001_m_000000_0 decomp: 568 len: 572 to MEMORY
2021-12-26 18:25:08,293 INFO [localfetcher#1] o.a.h.m.t.reduce.InMemoryMapOutput [InMemoryMapOutput.java : 94] Read 568 bytes from map-output for attempt_local1686705408_0001_m_000000_0
2021-12-26 18:25:08,294 INFO [localfetcher#1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 323] closeInMemoryFile -> map-output of size: 568, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->568
2021-12-26 18:25:08,296 INFO [EventFetcher for fetching Map Completion Events] o.a.h.m.task.reduce.EventFetcher [EventFetcher.java : 76] EventFetcher is interrupted.. Returning
2021-12-26 18:25:08,296 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 18:25:08,296 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 695] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-12-26 18:25:08,303 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 18:25:08,303 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 557 bytes
2021-12-26 18:25:08,305 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 762] Merged 1 segments, 568 bytes to disk to satisfy reduce memory limit
2021-12-26 18:25:08,306 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 792] Merging 1 files, 572 bytes from disk
2021-12-26 18:25:08,307 INFO [pool-8-thread-1] o.a.h.m.task.reduce.MergeManagerImpl [MergeManagerImpl.java : 807] Merging 0 segments, 0 bytes from memory into reduce
2021-12-26 18:25:08,307 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 606] Merging 1 sorted segments
2021-12-26 18:25:08,309 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Merger [Merger.java : 705] Down to the last merge-pass, with 1 segments left of total size: 557 bytes
2021-12-26 18:25:08,309 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 18:25:08,725 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1640] Job job_local1686705408_0001 running in uber mode : false
2021-12-26 18:25:08,729 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 0%
2021-12-26 18:25:08,854 INFO [pool-8-thread-1] o.a.h.conf.Configuration.deprecation [Configuration.java : 1395] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-12-26 18:25:08,860 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 31] reduce text key = 10000001, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@4ed3c73e, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@62e8b9ca
2021-12-26 18:25:08,860 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 66] context.write = OrderInfo(orderId=0, orderDate=, pid=10000001, amount=0, pname=小米2, categoryId=1, price=100.0, flag=1), data = (null)
2021-12-26 18:25:08,860 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 31] reduce text key = 100000010, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@4ed3c73e, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@62e8b9ca
2021-12-26 18:25:08,862 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 66] context.write = OrderInfo(orderId=0, orderDate=, pid=100000010, amount=0, pname=onePlus8, categoryId=11, price=1100.0, flag=1), data = (null)
2021-12-26 18:25:08,862 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 31] reduce text key = 10000002, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@4ed3c73e, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@62e8b9ca
2021-12-26 18:25:08,862 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 66] context.write = OrderInfo(orderId=0, orderDate=, pid=10000002, amount=0, pname=苹果8, categoryId=12, price=100.0, flag=1), data = (null)
2021-12-26 18:25:08,862 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 31] reduce text key = 10000003, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@4ed3c73e, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@62e8b9ca
2021-12-26 18:25:08,862 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 66] context.write = OrderInfo(orderId=0, orderDate=, pid=10000003, amount=0, pname=苹果8S, categoryId=31, price=1400.0, flag=1), data = (null)
2021-12-26 18:25:08,862 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 31] reduce text key = 10000004, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@4ed3c73e, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@62e8b9ca
2021-12-26 18:25:08,863 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 66] context.write = OrderInfo(orderId=0, orderDate=, pid=10000004, amount=0, pname=华为P50, categoryId=11, price=1300.0, flag=1), data = (null)
2021-12-26 18:25:08,863 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 31] reduce text key = 10000005, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@4ed3c73e, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@62e8b9ca
2021-12-26 18:25:08,863 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 66] context.write = OrderInfo(orderId=0, orderDate=, pid=10000005, amount=0, pname=华为P40, categoryId=13, price=5100.0, flag=1), data = (null)
2021-12-26 18:25:08,863 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 31] reduce text key = 10000006, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@4ed3c73e, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@62e8b9ca
2021-12-26 18:25:08,863 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 66] context.write = OrderInfo(orderId=0, orderDate=, pid=10000006, amount=0, pname=苹果11Pro, categoryId=11, price=4100.0, flag=1), data = (null)
2021-12-26 18:25:08,863 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 31] reduce text key = 10000007, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@4ed3c73e, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@62e8b9ca
2021-12-26 18:25:08,863 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 66] context.write = OrderInfo(orderId=0, orderDate=, pid=10000007, amount=0, pname=MacBook, categoryId=13, price=3100.0, flag=1), data = (null)
2021-12-26 18:25:08,863 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 31] reduce text key = 10000008, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@4ed3c73e, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@62e8b9ca
2021-12-26 18:25:08,863 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 66] context.write = OrderInfo(orderId=0, orderDate=, pid=10000008, amount=0, pname=肉松饼, categoryId=11, price=1100.0, flag=1), data = (null)
2021-12-26 18:25:08,864 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 31] reduce text key = 10000009, values = org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable@4ed3c73e, context = org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context@62e8b9ca
2021-12-26 18:25:08,865 INFO [pool-8-thread-1] c.b.hadoop.reduce.mapper.JoinReduce [JoinReduce.java : 66] context.write = OrderInfo(orderId=0, orderDate=, pid=10000009, amount=0, pname=方便面, categoryId=13, price=1020.0, flag=1), data = (null)
2021-12-26 18:25:09,207 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1232] Task:attempt_local1686705408_0001_r_000000_0 is done. And is in the process of committing
2021-12-26 18:25:09,208 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] 1 / 1 copied.
2021-12-26 18:25:09,208 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1409] Task attempt_local1686705408_0001_r_000000_0 is allowed to commit now
2021-12-26 18:25:09,324 INFO [pool-8-thread-1] o.a.h.m.l.output.FileOutputCommitter [FileOutputCommitter.java : 598] Saved output of task 'attempt_local1686705408_0001_r_000000_0' to hdfs://localhost:9000/output/product
2021-12-26 18:25:09,326 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 628] reduce > reduce
2021-12-26 18:25:09,327 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1368] Task 'attempt_local1686705408_0001_r_000000_0' done.
2021-12-26 18:25:09,329 INFO [pool-8-thread-1] org.apache.hadoop.mapred.Task [Task.java : 1264] Final Counters for attempt_local1686705408_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1353
		FILE: Number of bytes written=495116
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=270
		HDFS: Number of bytes written=1122
		HDFS: Number of read operations=14
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=572
		Reduce input records=10
		Reduce output records=10
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=642777088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=1122
2021-12-26 18:25:09,329 INFO [pool-8-thread-1] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 353] Finishing task: attempt_local1686705408_0001_r_000000_0
2021-12-26 18:25:09,330 INFO [Thread-18] o.a.hadoop.mapred.LocalJobRunner [LocalJobRunner.java : 486] reduce task executor complete.
2021-12-26 18:25:09,732 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1647]  map 100% reduce 100%
2021-12-26 18:25:10,745 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1658] Job job_local1686705408_0001 completed successfully
2021-12-26 18:25:10,753 INFO [http-nio-8080-exec-1] org.apache.hadoop.mapreduce.Job [Job.java : 1665] Counters: 35
	File System Counters
		FILE: Number of bytes read=1530
		FILE: Number of bytes written=989660
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=540
		HDFS: Number of bytes written=1122
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=546
		Map output materialized bytes=572
		Input split bytes=115
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=572
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=189
		Total committed heap usage (bytes)=1285554176
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=270
	File Output Format Counters 
		Bytes Written=1122
